{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty-based sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tutorial, you learned how to implement a closed-loop experiment with random and grid sampling. However, these strategies don't use any information about what the model knows or doesn't know.\n",
    "\n",
    "**Uncertainty-based sampling** is a more intelligent strategy that:\n",
    "- Samples experimental conditions where the model is most uncertain\n",
    "- Maximizes information gain from each new observation\n",
    "- Efficiently explores the experimental space\n",
    "\n",
    "This approach is grounded in **Information Theory**:\n",
    "- **High uncertainty** = high entropy = low information\n",
    "- **Sampling high-uncertainty regions** = maximum information gain\n",
    "- **Reducing uncertainty** = reducing entropy = learning\n",
    "\n",
    "In this tutorial, you will learn to:\n",
    "- Use Gaussian Processes that naturally provide uncertainty estimates\n",
    "- Visualize uncertainty across the experimental space\n",
    "- Implement uncertainty-based sampling with AutoRA\n",
    "- Observe how uncertainty decreases cycle-by-cycle\n",
    "- Compare uncertainty sampling to random sampling\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from typing import List\n",
    "\n",
    "# Set the path to the project folder\n",
    "target_folder = os.path.abspath(os.path.join(os.getcwd(), '..'))  # Adjust path as needed\n",
    "if target_folder not in sys.path:\n",
    "    sys.path.append(target_folder)\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from autora.experimentalist.random import random_pool\n",
    "from autora.variable import Variable, VariableCollection\n",
    "\n",
    "from resources.synthetic import twoafc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the synthetic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic experiment parameters\n",
    "n_units = 10  # Number of synthetic participants\n",
    "noise_level = 0.  # noise added to the experiment runners observations\n",
    "\n",
    "# Sample parameters for each synthetic participant\n",
    "parameters = np.random.normal(1, 0.5, (n_units, 2))\n",
    "parameters = np.where(parameters < 0, 0.1, parameters)\n",
    "\n",
    "# Create the experiment\n",
    "experiment = twoafc(parameters, noise_level=noise_level)\n",
    "\n",
    "print(f\"Created experiment with {n_units} synthetic participants\")\n",
    "print(f\"Noise level: {noise_level}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Gaussian Processes\n",
    "\n",
    "A **Gaussian Process (GP)** is a probabilistic model that naturally provides uncertainty estimates:\n",
    "- **Mean prediction**: The model's best guess for the response time\n",
    "- **Variance/uncertainty**: How confident the model is in its prediction\n",
    "\n",
    "Key properties:\n",
    "- **Near observed data**: Low uncertainty (the model has seen similar conditions)\n",
    "- **Far from observed data**: High uncertainty (the model hasn't explored this region)\n",
    "- **More data** → reduced uncertainty in those regions\n",
    "\n",
    "This makes GPs perfect for uncertainty-based sampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Gaussian Process model\n",
    "# The kernel controls how the model generalizes:\n",
    "# - RBF kernel: assumes smooth functions\n",
    "# - ConstantKernel: scales the output\n",
    "\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=0.5, length_scale_bounds=(1e-2, 1e2))\n",
    "theorist = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=2, alpha=1e-6)\n",
    "\n",
    "print(\"Gaussian Process model initialized\")\n",
    "print(f\"Kernel: {kernel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function for visualization\n",
    "\n",
    "Let's create a helper function to visualize predictions and uncertainty for a single participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_and_uncertainty(experiment, model, participant_id, conditions_sampled=None, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plot model predictions and uncertainty for a specific participant.\n",
    "    \n",
    "    Args:\n",
    "        experiment: The experiment runner\n",
    "        model: Trained Gaussian Process model\n",
    "        participant_id: Which participant to visualize\n",
    "        conditions_sampled: Array of sampled conditions to overlay (optional)\n",
    "        title: Title prefix for the plots\n",
    "    \"\"\"\n",
    "    # Create a grid of conditions to evaluate\n",
    "    ratio = np.linspace(0, 1, 50)\n",
    "    scatteredness = np.linspace(0, 1, 50)\n",
    "    ratio_mesh, scatteredness_mesh = np.meshgrid(ratio, scatteredness)\n",
    "    \n",
    "    # Prepare input for the model: [participant_id, ratio, scatteredness]\n",
    "    grid_conditions = np.column_stack([\n",
    "        # np.full(ratio_mesh.ravel().shape, participant_id),\n",
    "        ratio_mesh.ravel(),\n",
    "        scatteredness_mesh.ravel()\n",
    "    ])\n",
    "    \n",
    "    # Get predictions and uncertainty (std) from the GP\n",
    "    predictions, std = model.predict(grid_conditions, return_std=True)\n",
    "    predictions = predictions.reshape(ratio_mesh.shape)\n",
    "    uncertainty = std.reshape(ratio_mesh.shape)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    # Plot 1: 3D surface of predictions\n",
    "    ax1 = fig.add_subplot(131, projection='3d')\n",
    "    ax1.plot_surface(ratio_mesh, scatteredness_mesh, predictions, cmap=cm.viridis, alpha=0.8)\n",
    "    ax1.set_xlabel('Ratio')\n",
    "    ax1.set_ylabel('Scatteredness')\n",
    "    ax1.set_zlabel('Response Time')\n",
    "    ax1.set_title(f'{title}\\nPredictions (Participant {participant_id})')\n",
    "    \n",
    "    # Plot 2: Uncertainty heatmap\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    im = ax2.contourf(ratio_mesh, scatteredness_mesh, uncertainty, levels=20, cmap='YlOrRd')\n",
    "    ax2.set_xlabel('Ratio')\n",
    "    ax2.set_ylabel('Scatteredness')\n",
    "    ax2.set_title(f'{title}\\nUncertainty (Std Dev)')\n",
    "    plt.colorbar(im, ax=ax2, label='Uncertainty')\n",
    "    \n",
    "    # Overlay sampled conditions if provided\n",
    "    if conditions_sampled is not None:\n",
    "        # Filter conditions for this participant\n",
    "        participant_conditions = conditions_sampled[conditions_sampled[:, 0] == participant_id]\n",
    "        if len(participant_conditions) > 0:\n",
    "            ax2.scatter(participant_conditions[:, 1], participant_conditions[:, 2], \n",
    "                       c='blue', s=30, marker='x', linewidths=2, label='Sampled', zorder=5)\n",
    "            ax2.legend()\n",
    "    \n",
    "    # Plot 3: Predictions with uncertainty bands (slice at scatteredness=0.5)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    mid_idx = len(scatteredness) // 2\n",
    "    pred_slice = predictions[mid_idx, :]\n",
    "    unc_slice = uncertainty[mid_idx, :]\n",
    "    \n",
    "    ax3.plot(ratio, pred_slice, 'b-', linewidth=2, label='Mean prediction')\n",
    "    ax3.fill_between(ratio, pred_slice - 2*unc_slice, pred_slice + 2*unc_slice, \n",
    "                     alpha=0.3, color='blue', label='95% confidence')\n",
    "    ax3.set_xlabel('Ratio')\n",
    "    ax3.set_ylabel('Response Time')\n",
    "    ax3.set_title(f'{title}\\nSlice at Scatteredness=0.5')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print uncertainty statistics\n",
    "    print(f\"Mean uncertainty: {uncertainty.mean():.4f}\")\n",
    "    print(f\"Max uncertainty: {uncertainty.max():.4f}\")\n",
    "    print(f\"Min uncertainty: {uncertainty.min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle 0: Initial random sampling\n",
    "\n",
    "Let's start with an initial set of random conditions and see what the uncertainty looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.experimentalist.random import random_pool\n",
    "\n",
    "# Generate initial random conditions\n",
    "n_samples_per_cycle = 5\n",
    "conditions = random_pool(experiment.variables, n_samples_per_cycle).to_numpy()\n",
    "\n",
    "print(f\"Generated {len(conditions)} initial random conditions\")\n",
    "print(f\"Condition shape: {conditions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment and collect data\n",
    "experiment_data = experiment.run(conditions, random_state=42).to_numpy()\n",
    "\n",
    "# Extract features (X) and target (y)\n",
    "n_dv = len(experiment.variables.dependent_variables)\n",
    "X = experiment_data[:, 1:-n_dv]\n",
    "y = experiment_data[:, -n_dv:]\n",
    "\n",
    "# Fit the Gaussian Process\n",
    "theorist.fit(X, y)\n",
    "\n",
    "print(f\"\\nCycle 0 completed: {len(X)} total samples\")\n",
    "print(f\"Model fitted on data with shape X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Cycle 0 results\n",
    "\n",
    "Let's visualize the predictions and uncertainty after the initial random sampling. Notice:\n",
    "- **High uncertainty** in regions far from sampled points\n",
    "- **Lower uncertainty** near sampled points\n",
    "- The model is **uncertain about most of the space** because we've only sampled 50 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_and_uncertainty(\n",
    "    experiment=experiment,\n",
    "    model=theorist,\n",
    "    participant_id=0,\n",
    "    conditions_sampled=conditions,\n",
    "    title=\"Cycle 0: Initial Random Sampling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty sampler\n",
    "\n",
    "In order to make use of the uncertainty estimate of the Gaussian Process, we have to implement an experimentalist which samples the next conditions in the areas of highest uncertainty.\n",
    "\n",
    "Follow the next steps in order to implement your first own experimentalist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_sample(conditions: VariableCollection, model, num_samples=1, pool_size=10000, random_state=None):\n",
    "    \"\"\"\n",
    "    Sample experimental condition(s) with highest GP uncertainty.\n",
    "    \n",
    "    Samples one point at a time based on maximum standard deviation from the GP.\n",
    "    For multiple samples, this function should be called iteratively with model\n",
    "    refitting between calls to ensure diversity.\n",
    "    \n",
    "    Args:\n",
    "        conditions: AutoRA VariableCollection describing experimental space\n",
    "        model: Trained GaussianProcessRegressor with predict(X, return_std=True)\n",
    "        num_samples: Number of samples to return (default=1, keeping at 1 is recommended)\n",
    "        pool_size: Size of random candidate pool to evaluate (default=10000)\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with selected experimental condition(s)\n",
    "    \"\"\"\n",
    "    # Step 1: Generate candidate pool\n",
    "    candidate_pool = random_pool(conditions, pool_size, random_state=random_state).to_numpy()\n",
    "    \n",
    "    # Step 2: Get uncertainty estimates from GP\n",
    "    _, std = model.predict(candidate_pool, return_std=True)\n",
    "    \n",
    "    # Step 3: Select point(s) with highest uncertainty\n",
    "    if num_samples == 1:\n",
    "        # Most common case: select single highest uncertainty point\n",
    "        max_idx = np.argmax(std)\n",
    "        selected = candidate_pool[max_idx:max_idx+1]  # Keep 2D shape\n",
    "    else:\n",
    "        # For multiple samples: select top-k by uncertainty\n",
    "        # Note: This may cluster points! Better to call this function iteratively.\n",
    "        top_indices = np.argsort(std)[-num_samples:][::-1]\n",
    "        selected = candidate_pool[top_indices]\n",
    "    \n",
    "    # Return as DataFrame\n",
    "    ivs = conditions.independent_variables\n",
    "    column_names = [iv.name for iv in ivs]\n",
    "    return pd.DataFrame(selected, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively refining the model with uncertainty-based sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle 1\n",
    "\n",
    "Now let's use **uncertainty-based sampling** to select the next batch of conditions. The AutoRA uncertainty sampler will:\n",
    "1. Generate a pool of candidate conditions\n",
    "2. Use the GP to predict uncertainty for each candidate\n",
    "3. Select the conditions with the **highest uncertainty**\n",
    "\n",
    "This should focus sampling on regions where the model is most uncertain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use uncertainty sampling to select new conditions\n",
    "# The sampler needs a model that has a predict method returning mean and std\n",
    "new_conditions = uncertainty_sample(\n",
    "    conditions=experiment.variables,\n",
    "    model=theorist,\n",
    ").to_numpy()\n",
    "\n",
    "print(f\"Sampled {len(new_conditions)} new conditions based on uncertainty:\")\n",
    "print(f\"{new_conditions[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment on new conditions\n",
    "new_data = experiment.run(new_conditions, random_state=43).to_numpy()\n",
    "\n",
    "# Combine with previous data\n",
    "experiment_data = np.vstack([experiment_data, new_data])\n",
    "conditions = np.vstack([conditions, new_conditions])\n",
    "\n",
    "# Extract features and target\n",
    "X = experiment_data[:, 1:-n_dv]\n",
    "y = experiment_data[:, -n_dv:].ravel()\n",
    "\n",
    "# Refit the Gaussian Process with all data\n",
    "theorist.fit(X, y)\n",
    "\n",
    "print(f\"\\nCycle 1 completed: {len(X)} total samples\")\n",
    "print(f\"Model refitted on accumulated data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Cycle 1 results**\n",
    "\n",
    "Compare to Cycle 0. You should see:\n",
    "- **Reduced uncertainty** in regions that were previously uncertain\n",
    "- Uncertainty-based sampling **targeted high-uncertainty regions**\n",
    "- More **efficient exploration** compared to random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_and_uncertainty(\n",
    "    experiment=experiment,\n",
    "    model=theorist,\n",
    "    participant_id=0,\n",
    "    conditions_sampled=conditions,\n",
    "    title=\"Cycle 1: After Uncertainty Sampling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle 2\n",
    "\n",
    "Let's continue for another cycle to see how uncertainty continues to decrease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty sampling for cycle 2\n",
    "new_conditions = uncertainty_sample(\n",
    "    conditions=experiment.variables,\n",
    "    model=theorist,\n",
    ").to_numpy()\n",
    "\n",
    "# Run experiment\n",
    "new_data = experiment.run(new_conditions, random_state=44).to_numpy()\n",
    "\n",
    "# Accumulate data\n",
    "experiment_data = np.vstack([experiment_data, new_data])\n",
    "conditions = np.vstack([conditions, new_conditions])\n",
    "\n",
    "# Refit model\n",
    "X = experiment_data[:, 1:-n_dv]\n",
    "y = experiment_data[:, -n_dv:].ravel()\n",
    "theorist.fit(X, y)\n",
    "\n",
    "print(f\"New condition: {new_conditions[:5]}\")\n",
    "print(f\"Cycle 2 completed: {len(X)} total samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Cycle 2 results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_and_uncertainty(\n",
    "    experiment=experiment,\n",
    "    model=theorist,\n",
    "    participant_id=0,\n",
    "    conditions_sampled=conditions,\n",
    "    title=\"Cycle 2: Further Refinement\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle 3\n",
    "\n",
    "One more cycle to see how low we can get the uncertainty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty sampling for cycle 3\n",
    "new_conditions = uncertainty_sample(\n",
    "    conditions=experiment.variables,\n",
    "    model=theorist,\n",
    ").to_numpy()\n",
    "\n",
    "# Run experiment\n",
    "new_data = experiment.run(new_conditions, random_state=45).to_numpy()\n",
    "\n",
    "# Accumulate data\n",
    "experiment_data = np.vstack([experiment_data, new_data])\n",
    "conditions = np.vstack([conditions, new_conditions])\n",
    "\n",
    "# Refit model\n",
    "X = experiment_data[:, 1:-n_dv]\n",
    "y = experiment_data[:, -n_dv:].ravel()\n",
    "theorist.fit(X, y)\n",
    "\n",
    "print(f\"New condition: {new_conditions[:5]}\")\n",
    "print(f\"Cycle 3 completed: {len(X)} total samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Cycle 3 results\n",
    "\n",
    "After 4 cycles (200 samples), the uncertainty should be substantially reduced across most of the experimental space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_and_uncertainty(\n",
    "    experiment=experiment,\n",
    "    model=theorist,\n",
    "    participant_id=0,\n",
    "    conditions_sampled=conditions,\n",
    "    title=\"Cycle 3: Near-Complete Coverage\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Uncertainty vs Random Sampling\n",
    "\n",
    "Now let's compare uncertainty-based sampling to random sampling with the same number of samples. This will show us whether uncertainty sampling is truly more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new GP model for random sampling\n",
    "kernel_random = C(1.0, (1e-3, 1e3)) * RBF(length_scale=0.5, length_scale_bounds=(1e-2, 1e2))\n",
    "theorist_random = GaussianProcessRegressor(kernel=kernel_random, n_restarts_optimizer=2, alpha=1e-6)\n",
    "\n",
    "# Generate all random conditions at once (same total number as uncertainty sampling)\n",
    "total_samples = len(conditions)\n",
    "conditions_random = random_pool(experiment.variables, total_samples).to_numpy()\n",
    "\n",
    "# Run experiment on all random conditions\n",
    "experiment_data_random = experiment.run(conditions_random, random_state=100).to_numpy()\n",
    "\n",
    "# Fit the model\n",
    "X_random = experiment_data_random[:, 1:-n_dv]\n",
    "y_random = experiment_data_random[:, -n_dv:].ravel()\n",
    "theorist_random.fit(X_random, y_random)\n",
    "\n",
    "print(f\"Random sampling completed with {len(X_random)} samples\")\n",
    "print(f\"Same as uncertainty sampling: {len(X)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize comparison\n",
    "\n",
    "Let's create a side-by-side comparison of uncertainty maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_uncertainty_maps(experiment, model_unc, model_rand, participant_id, cond_unc, cond_rand):\n",
    "    \"\"\"\n",
    "    Side-by-side comparison of uncertainty maps.\n",
    "    \"\"\"\n",
    "    # Create grid\n",
    "    ratio = np.linspace(0, 1, 50)\n",
    "    scatteredness = np.linspace(0, 1, 50)\n",
    "    ratio_mesh, scatteredness_mesh = np.meshgrid(ratio, scatteredness)\n",
    "    \n",
    "    grid_conditions = np.column_stack([\n",
    "        # np.full(ratio_mesh.ravel().shape, participant_id),\n",
    "        ratio_mesh.ravel(),\n",
    "        scatteredness_mesh.ravel()\n",
    "    ])\n",
    "    \n",
    "    # Get predictions and uncertainty from both models\n",
    "    _, std_unc = model_unc.predict(grid_conditions, return_std=True)\n",
    "    _, std_rand = model_rand.predict(grid_conditions, return_std=True)\n",
    "    \n",
    "    uncertainty_unc = std_unc.reshape(ratio_mesh.shape)\n",
    "    uncertainty_rand = std_rand.reshape(ratio_mesh.shape)\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Use same color scale for fair comparison\n",
    "    vmax = max(uncertainty_unc.max(), uncertainty_rand.max())\n",
    "    \n",
    "    # Uncertainty sampling\n",
    "    im1 = ax1.contourf(ratio_mesh, scatteredness_mesh, uncertainty_unc, levels=20, cmap='YlOrRd', vmax=vmax)\n",
    "    participant_cond_unc = cond_unc[cond_unc[:, 0] == participant_id]\n",
    "    if len(participant_cond_unc) > 0:\n",
    "        ax1.scatter(participant_cond_unc[:, 1], participant_cond_unc[:, 2], \n",
    "                   c='blue', s=20, marker='x', linewidths=1.5, alpha=0.6)\n",
    "    ax1.set_xlabel('Ratio')\n",
    "    ax1.set_ylabel('Scatteredness')\n",
    "    ax1.set_title(f'Uncertainty Sampling\\n(Participant {participant_id})')\n",
    "    plt.colorbar(im1, ax=ax1, label='Uncertainty')\n",
    "    \n",
    "    # Random sampling\n",
    "    im2 = ax2.contourf(ratio_mesh, scatteredness_mesh, uncertainty_rand, levels=20, cmap='YlOrRd', vmax=vmax)\n",
    "    participant_cond_rand = cond_rand[cond_rand[:, 0] == participant_id]\n",
    "    if len(participant_cond_rand) > 0:\n",
    "        ax2.scatter(participant_cond_rand[:, 1], participant_cond_rand[:, 2], \n",
    "                   c='blue', s=20, marker='x', linewidths=1.5, alpha=0.6)\n",
    "    ax2.set_xlabel('Ratio')\n",
    "    ax2.set_ylabel('Scatteredness')\n",
    "    ax2.set_title(f'Random Sampling\\n(Participant {participant_id})')\n",
    "    plt.colorbar(im2, ax=ax2, label='Uncertainty')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nUncertainty Statistics:\")\n",
    "    print(f\"Uncertainty Sampling - Mean: {uncertainty_unc.mean():.4f}, Max: {uncertainty_unc.max():.4f}\")\n",
    "    print(f\"Random Sampling      - Mean: {uncertainty_rand.mean():.4f}, Max: {uncertainty_rand.max():.4f}\")\n",
    "    print(f\"\\nReduction in mean uncertainty: {(uncertainty_rand.mean() - uncertainty_unc.mean()) / uncertainty_rand.mean() * 100:.1f}%\")\n",
    "\n",
    "compare_uncertainty_maps(\n",
    "    experiment=experiment,\n",
    "    model_unc=theorist,\n",
    "    model_rand=theorist_random,\n",
    "    participant_id=0,\n",
    "    cond_unc=conditions,\n",
    "    cond_rand=conditions_random\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative comparison\n",
    "\n",
    "Let's also compare the models on held-out test data to see which strategy learned better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test conditions\n",
    "test_conditions = random_pool(experiment.variables, 500).to_numpy()\n",
    "test_data = experiment.run(test_conditions, random_state=999).to_numpy()\n",
    "\n",
    "X_test = test_data[:, 1:-n_dv]\n",
    "y_test = test_data[:, -n_dv:]\n",
    "\n",
    "# Predictions from both models\n",
    "y_pred_unc = theorist.predict(X_test)\n",
    "y_pred_rand = theorist_random.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_unc = np.mean((y_test - y_pred_unc)**2)\n",
    "mse_rand = np.mean((y_test - y_pred_rand)**2)\n",
    "\n",
    "# Calculate R²\n",
    "from sklearn.metrics import r2_score\n",
    "r2_unc = r2_score(y_test, y_pred_unc)\n",
    "r2_rand = r2_score(y_test, y_pred_rand)\n",
    "\n",
    "print(\"Test Set Performance (500 samples):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Uncertainty Sampling - MSE: {mse_unc:.6f}, R²: {r2_unc:.4f}\")\n",
    "print(f\"Random Sampling      - MSE: {mse_rand:.6f}, R²: {r2_rand:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Improvement in MSE: {(mse_rand - mse_unc) / mse_rand * 100:.1f}%\")\n",
    "print(f\"Improvement in R²: {(r2_unc - r2_rand) / (1 - r2_rand) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the quantitative comparison look like? \n",
    "\n",
    "Is the uncertainty sampler any better?\n",
    "\n",
    "**Challenge:**\n",
    "Find use-cases where it's actually outperforming random sampling by a good margin!\n",
    "\n",
    "Implement your own closed-loop as you know it from the previous AutoRA tutorial.\n",
    "\n",
    "Set up the 2AFC experiment with a different noise level and sample one experimental condition at a time with the uncertainty sampler and the random sampler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-disagreement sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will implement your own **model-disagreement sampler**.\n",
    "\n",
    "Model-disagreement sampling approximates the uncertainty estimate without direct access to an uncertainty computation.\n",
    "\n",
    "That makes this sampling technique amenable to any type of regressor or classifier.\n",
    "\n",
    "Disagreement is a distance measure for the prediction of an ensemble of models.\n",
    "\n",
    "This ensemble can contain either (1) a set of different models or (2) a set of the same model type but with different random initializations.\n",
    "\n",
    "We are going to apply it to the second case. Here, we are going to pack a number of `FFNRegressor` into a `list` in order to get an ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup of the 2AFC experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 10\n",
    "n_conditions = 2\n",
    "\n",
    "# ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup of the theorist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources.regressors import FFN, FFNRegressor\n",
    "\n",
    "n_models = 5\n",
    "\n",
    "ensemble = []\n",
    "for _ in range(n_models):\n",
    "    ensemble.append(\n",
    "        FFNRegressor(\n",
    "            FFN(n_units=n_units, n_conditions=n_conditions),\n",
    "            max_epochs=100,\n",
    "            lr=0.1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setup a random experimentalist to get an initial set of conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit the ensemble to the initial set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment with the new set of conditions to get the first observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the ensemble to the experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dv = len(experiment.variables.dependent_variables)\n",
    "conditions = experiment_data[:, :-n_dv]\n",
    "observations = experiment_data[:, -n_dv:]\n",
    "\n",
    "for index_model, model in enumerate(ensemble):\n",
    "    ensemble[index_model].fit(conditions, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Implement the model disagreement sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement_sampler(experiment, ensemble: List[BaseEstimator], num_samples=1, pool_size=10000) -> pd.DataFrame:\n",
    "    new_conditions = None\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    # 1. set the arrays of the conditions given the value ranges in the experiment\n",
    "    # 2. get the experiment data from the experiment run in order to have the unit ids aligned with the conditions \n",
    "    #       -> the FFNRegressor takes also unit ids as inputs to account for individual differences\n",
    "    # 3. get the predictions of each model in the ensemble\n",
    "    # 4. compute model disagreement as the average euler distance between the predictions for each condition\n",
    "    # 5. determine the num_samples conditions with the highest model disagreement\n",
    "    \n",
    "    return new_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Set up the closed-loop with your custom sampler and a random sampler to determine which one is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
