{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Advanced Active Learning: Model Disagreement\n",
        "\n",
        "Welcome to advanced active learning! In this tutorial, you'll learn how to use **model ensembles** and **disagreement-based sampling** for even more sophisticated experimental design.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "- Understand the difference between uncertainty and disagreement sampling\n",
        "- Build model ensembles (committees) for disagreement estimation\n",
        "- Implement query-by-committee with AutoRA's disagreement experimentalist\n",
        "- Compare uncertainty vs. disagreement strategies\n",
        "- Understand when to use each active learning approach\n",
        "\n",
        "## Uncertainty vs. Disagreement: What's the Difference?\n",
        "\n",
        "### Uncertainty Sampling (Previous Tutorial)\n",
        "- Uses a **single model** (e.g., Gaussian Process)\n",
        "- Queries where model is most uncertain: $\\arg\\max_x \\sigma(x)$\n",
        "- Works well when model can accurately estimate its own uncertainty\n",
        "\n",
        "### Disagreement Sampling (This Tutorial)\n",
        "- Uses **multiple models** (ensemble/committee)\n",
        "- Queries where models disagree most: $\\arg\\max_x \\text{Var}(\\{f_1(x), f_2(x), ..., f_K(x)\\})$\n",
        "- More robust when individual models might be miscalibrated\n",
        "\n",
        "### Key Insight\n",
        "\n",
        "**Disagreement captures epistemic uncertainty** (what we don't know) rather than aleatoric uncertainty (inherent noise).\n",
        "\n",
        "When models disagree, it means:\n",
        "- The data doesn't strongly constrain the model in that region\n",
        "- We need more observations to resolve the disagreement\n",
        "- This is **highly informative** for learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": [
        "## Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress training warnings for cleaner output\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Add project folder to path\n",
        "target_folder = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "if target_folder not in sys.path:\n",
        "    sys.path.append(target_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## Part 1: Building a Model Ensemble\n",
        "\n",
        "To use disagreement sampling, we need multiple models that can provide diverse predictions. We'll create an **ensemble** of neural networks.\n",
        "\n",
        "### Why Neural Network Ensembles?\n",
        "\n",
        "1. **Diversity**: Different random initializations lead to different learned functions\n",
        "2. **Flexibility**: Can model complex, non-linear relationships\n",
        "3. **Familiarity**: Students already know FFNRegressor from earlier tutorials\n",
        "4. **Scalability**: Works well with high-dimensional data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from resources.regressors import FFN, FFNRegressor\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class FFNEnsemble(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"\n",
        "    Ensemble of Feed-Forward Neural Networks\n",
        "    \n",
        "    Each model is trained independently with different random initialization.\n",
        "    Predictions are averaged, and disagreement is measured by variance.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_units, input_dim, n_models=5, max_epochs=50, lr=0.1, verbose=False):\n",
        "        self.n_units = n_units\n",
        "        self.input_dim = input_dim\n",
        "        self.n_models = n_models\n",
        "        self.max_epochs = max_epochs\n",
        "        self.lr = lr\n",
        "        self.verbose = verbose\n",
        "        self.models = []\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train ensemble of models\"\"\"\n",
        "        self.models = []\n",
        "        \n",
        "        for i in range(self.n_models):\n",
        "            # Create model with different random seed\n",
        "            model = FFNRegressor(\n",
        "                FFN(self.n_units, self.input_dim),\n",
        "                max_epochs=self.max_epochs,\n",
        "                lr=self.lr,\n",
        "                verbose=self.verbose\n",
        "            )\n",
        "            \n",
        "            # Train on full dataset (could also use bootstrap samples)\n",
        "            model.fit(X, y)\n",
        "            self.models.append(model)\n",
        "            \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X, return_std=False):\n",
        "        \"\"\"Make predictions with ensemble\"\"\"\n",
        "        # Get predictions from all models\n",
        "        predictions = np.array([model.predict(X) for model in self.models])\n",
        "        \n",
        "        # Average predictions\n",
        "        mean_pred = np.mean(predictions, axis=0)\n",
        "        \n",
        "        if return_std:\n",
        "            # Standard deviation across models = disagreement\n",
        "            std_pred = np.std(predictions, axis=0)\n",
        "            return mean_pred, std_pred\n",
        "        else:\n",
        "            return mean_pred\n",
        "    \n",
        "    def get_params(self, deep=True):\n",
        "        \"\"\"Required for sklearn compatibility\"\"\"\n",
        "        return {\n",
        "            'n_units': self.n_units,\n",
        "            'input_dim': self.input_dim,\n",
        "            'n_models': self.n_models,\n",
        "            'max_epochs': self.max_epochs,\n",
        "            'lr': self.lr,\n",
        "            'verbose': self.verbose\n",
        "        }\n",
        "    \n",
        "    def set_params(self, **params):\n",
        "        \"\"\"Required for sklearn compatibility\"\"\"\n",
        "        for key, value in params.items():\n",
        "            setattr(self, key, value)\n",
        "        return self\n",
        "\n",
        "print(\"âœ“ FFNEnsemble class created!\")\n",
        "print(\"\\nKey methods:\")\n",
        "print(\"  - fit(X, y): Train all models in ensemble\")\n",
        "print(\"  - predict(X, return_std=True): Get mean prediction and disagreement\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": [
        "### Testing the Ensemble on Simple 1D Data\n",
        "\n",
        "Let's visualize how ensemble disagreement works on a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create simple 1D ground truth\n",
        "def ground_truth_1d(x):\n",
        "    return np.sin(3 * x) + 0.3 * np.cos(9 * x)\n",
        "\n",
        "# Sample sparse training data\n",
        "X_train_1d = np.array([[0.1], [0.3], [0.7], [0.9]])\n",
        "y_train_1d = ground_truth_1d(X_train_1d.ravel())\n",
        "\n",
        "# Note: For 1D demo, we use input_dim=1 and n_units=1 (no participant ID)\n",
        "ensemble_1d = FFNEnsemble(\n",
        "    n_units=1,  # Single \"pseudo-unit\" for 1D case\n",
        "    input_dim=1,\n",
        "    n_models=5,\n",
        "    max_epochs=100,\n",
        "    lr=0.05,\n",
        "    verbose=False\n",
        ")\n",
        "ensemble_1d.fit(X_train_1d, y_train_1d)\n",
        "\n",
        "# Make predictions\n",
        "X_test_1d = np.linspace(0, 1, 200).reshape(-1, 1)\n",
        "y_pred, y_std = ensemble_1d.predict(X_test_1d, return_std=True)\n",
        "\n",
        "# Visualize individual models and ensemble\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot individual model predictions\n",
        "for i, model in enumerate(ensemble_1d.models):\n",
        "    y_individual = model.predict(X_test_1d)\n",
        "    plt.plot(X_test_1d, y_individual, alpha=0.3, linewidth=1, color='blue')\n",
        "\n",
        "# Plot ensemble mean and disagreement\n",
        "plt.fill_between(X_test_1d.ravel(), \n",
        "                 y_pred - 2*y_std, \n",
        "                 y_pred + 2*y_std, \n",
        "                 alpha=0.3, \n",
        "                 color='red',\n",
        "                 label='Disagreement (Â±2Ïƒ)')\n",
        "plt.plot(X_test_1d, y_pred, 'r-', linewidth=2, label='Ensemble Mean')\n",
        "plt.plot(X_test_1d, ground_truth_1d(X_test_1d.ravel()), 'k--', linewidth=2, label='True Function')\n",
        "plt.scatter(X_train_1d, y_train_1d, c='green', s=200, zorder=10, edgecolors='black', linewidths=2, label='Training Data')\n",
        "plt.xlabel('x', fontsize=12)\n",
        "plt.ylabel('y', fontsize=12)\n",
        "plt.title('Ensemble Disagreement: Individual Models vs. Ensemble', fontsize=14)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"Key Observations:\")\n",
        "print(\"  - Blue lines: Individual model predictions (diverse!)\")\n",
        "print(\"  - Red line: Ensemble mean (averaged prediction)\")\n",
        "print(\"  - Red band: Disagreement (where models disagree)\")\n",
        "print(\"  - Disagreement is HIGH far from training data\")\n",
        "print(\"  - Disagreement is LOW near training data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "## Part 2: AutoRA Disagreement Experimentalist\n",
        "\n",
        "Now let's use AutoRA's built-in disagreement experimentalist with our 2AFC experiment.\n",
        "\n",
        "### Installation\n",
        "\n",
        "Make sure you have the disagreement experimentalist installed:\n",
        "\n",
        "```bash\n",
        "pip install -U \"autora[experimentalist-inequality]\"\n",
        "```\n",
        "\n",
        "Note: In AutoRA, disagreement sampling is part of the \"inequality\" experimentalist package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from resources.synthetic import twoafc\n",
        "from autora.state import StandardState, on_state, estimator_on_state\n",
        "from autora.experimentalist.random import random_sample\n",
        "from autora.experimentalist.pooler import grid_pool\n",
        "\n",
        "# Import disagreement experimentalist\n",
        "try:\n",
        "    from autora.experimentalist.inequality import inequality_sample\n",
        "    print(\"âœ“ Disagreement (inequality) experimentalist imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(\"âœ— Error importing disagreement experimentalist.\")\n",
        "    print(\"  Please install with: pip install -U 'autora[experimentalist-inequality]'\")\n",
        "    raise e\n",
        "\n",
        "# Define participant parameters\n",
        "n_units = 100\n",
        "parameters = np.random.normal(1, 0.5, (n_units, 2))\n",
        "parameters = np.where(parameters < 0, 0, parameters)\n",
        "\n",
        "# Create experiment\n",
        "experiment = twoafc(parameters, resolution=10)\n",
        "\n",
        "# Get variable names\n",
        "iv_names = [iv.name for iv in experiment.variables.independent_variables]\n",
        "dv_names = [dv.name for dv in experiment.variables.dependent_variables]\n",
        "\n",
        "print(\"\\nExperiment setup complete!\")\n",
        "print(f\"IVs: {iv_names}\")\n",
        "print(f\"DVs: {dv_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {},
      "source": [
        "## Part 3: Three-Way Comparison\n",
        "\n",
        "Let's compare three strategies:\n",
        "1. **Random sampling** (baseline)\n",
        "2. **Uncertainty sampling** (from previous tutorial)\n",
        "3. **Disagreement sampling** (new!)\n",
        "\n",
        "We'll run 10 cycles and track performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "### Strategy 1: Random Sampling (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "from resources.regressors import FFN, FFNRegressor\n",
        "\n",
        "# Wrap components\n",
        "experiment_runner = on_state(experiment.run, output=['experiment_data'])\n",
        "experimentalist_random = on_state(random_sample, output=['conditions'])\n",
        "\n",
        "# Create model\n",
        "model_random = FFNRegressor(FFN(n_units, 2), max_epochs=50, lr=0.1, verbose=False)\n",
        "theorist_random = estimator_on_state(model_random)\n",
        "\n",
        "# Initialize state\n",
        "state_random = StandardState(\n",
        "    variables=experiment.variables,\n",
        "    conditions=pd.DataFrame(columns=iv_names),\n",
        "    experiment_data=pd.DataFrame(columns=iv_names + dv_names),\n",
        "    models=[model_random]\n",
        ")\n",
        "\n",
        "# Run cycles\n",
        "n_cycles = 10\n",
        "samples_per_cycle = 5\n",
        "mse_history_random = []\n",
        "\n",
        "print(\"Running RANDOM sampling strategy...\\n\")\n",
        "\n",
        "for cycle in range(n_cycles):\n",
        "    state_random = experimentalist_random(\n",
        "        state_random,\n",
        "        num_samples=samples_per_cycle,\n",
        "        random_state=42+cycle,\n",
        "        sample_all=['participant_id']\n",
        "    )\n",
        "    state_random = experiment_runner(state_random, added_noise=0.0, random_state=42+cycle)\n",
        "    state_random = theorist_random(state_random)\n",
        "    \n",
        "    X = state_random.experiment_data[iv_names].values\n",
        "    y_true = state_random.experiment_data[dv_names].values.ravel()\n",
        "    y_pred = state_random.models[0].predict(X)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mse_history_random.append(mse)\n",
        "    \n",
        "    print(f\"Cycle {cycle+1:2d}/{n_cycles}: {len(state_random.experiment_data):4d} samples, MSE = {mse:.4f}\")\n",
        "\n",
        "print(\"\\nâœ“ Random sampling complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-12",
      "metadata": {},
      "source": [
        "### Strategy 2: Uncertainty Sampling (GP-based)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
        "from autora.experimentalist.uncertainty import uncertainty_sample\n",
        "\n",
        "# Wrap uncertainty experimentalist\n",
        "experimentalist_uncertainty = on_state(uncertainty_sample, output=['conditions'])\n",
        "pool_generator = on_state(grid_pool, output=['conditions'])\n",
        "\n",
        "# Create GP model\n",
        "kernel_uncertainty = C(1.0, (1e-3, 1e3)) * RBF([1.0, 1.0, 1.0], (1e-2, 1e2)) + WhiteKernel(noise_level=0.01)\n",
        "gp_uncertainty = GaussianProcessRegressor(\n",
        "    kernel=kernel_uncertainty,\n",
        "    n_restarts_optimizer=5,\n",
        "    random_state=42,\n",
        "    normalize_y=True\n",
        ")\n",
        "theorist_uncertainty = estimator_on_state(gp_uncertainty)\n",
        "\n",
        "# Initialize with seed data\n",
        "seed_conditions = random_sample(\n",
        "    experiment.variables,\n",
        "    num_samples=2,\n",
        "    random_state=42,\n",
        "    sample_all=['participant_id']\n",
        ")\n",
        "state_uncertainty = StandardState(\n",
        "    variables=experiment.variables,\n",
        "    conditions=seed_conditions,\n",
        "    experiment_data=pd.DataFrame(columns=iv_names + dv_names),\n",
        "    models=[gp_uncertainty]\n",
        ")\n",
        "\n",
        "state_uncertainty = experiment_runner(state_uncertainty, added_noise=0.0, random_state=42)\n",
        "state_uncertainty = theorist_uncertainty(state_uncertainty)\n",
        "\n",
        "mse_history_uncertainty = []\n",
        "\n",
        "X = state_uncertainty.experiment_data[iv_names].values\n",
        "y_true = state_uncertainty.experiment_data[dv_names].values.ravel()\n",
        "y_pred = state_uncertainty.models[0].predict(X)\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mse_history_uncertainty.append(mse)\n",
        "\n",
        "print(\"Running UNCERTAINTY sampling strategy...\\n\")\n",
        "print(f\"Cycle  0/{n_cycles}: {len(state_uncertainty.experiment_data):4d} samples (seed), MSE = {mse:.4f}\")\n",
        "\n",
        "for cycle in range(1, n_cycles):\n",
        "    pool_state = StandardState(\n",
        "        variables=experiment.variables,\n",
        "        conditions=pd.DataFrame(columns=iv_names),\n",
        "        experiment_data=state_uncertainty.experiment_data.copy(),\n",
        "        models=state_uncertainty.models\n",
        "    )\n",
        "    pool_state = pool_generator(pool_state, num_samples=20, sample_all=['participant_id'])\n",
        "    pool_state = experimentalist_uncertainty(pool_state, num_samples=samples_per_cycle)\n",
        "    \n",
        "    state_uncertainty.conditions = pool_state.conditions\n",
        "    state_uncertainty = experiment_runner(state_uncertainty, added_noise=0.0, random_state=42+cycle)\n",
        "    state_uncertainty = theorist_uncertainty(state_uncertainty)\n",
        "    \n",
        "    X = state_uncertainty.experiment_data[iv_names].values\n",
        "    y_true = state_uncertainty.experiment_data[dv_names].values.ravel()\n",
        "    y_pred = state_uncertainty.models[0].predict(X)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mse_history_uncertainty.append(mse)\n",
        "    \n",
        "    print(f\"Cycle {cycle:2d}/{n_cycles}: {len(state_uncertainty.experiment_data):4d} samples, MSE = {mse:.4f}\")\n",
        "\n",
        "print(\"\\nâœ“ Uncertainty sampling complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {},
      "source": [
        "### Strategy 3: Disagreement Sampling (Ensemble-based)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wrap disagreement experimentalist\n",
        "experimentalist_disagreement = on_state(inequality_sample, output=['conditions'])\n",
        "\n",
        "# Create ensemble model\n",
        "ensemble_model = FFNEnsemble(\n",
        "    n_units=n_units,\n",
        "    input_dim=2,  # ratio and scatteredness\n",
        "    n_models=5,\n",
        "    max_epochs=50,\n",
        "    lr=0.1,\n",
        "    verbose=False\n",
        ")\n",
        "theorist_disagreement = estimator_on_state(ensemble_model)\n",
        "\n",
        "# Initialize with seed data\n",
        "seed_conditions_disagreement = random_sample(\n",
        "    experiment.variables,\n",
        "    num_samples=2,\n",
        "    random_state=42,\n",
        "    sample_all=['participant_id']\n",
        ")\n",
        "state_disagreement = StandardState(\n",
        "    variables=experiment.variables,\n",
        "    conditions=seed_conditions_disagreement,\n",
        "    experiment_data=pd.DataFrame(columns=iv_names + dv_names),\n",
        "    models=[ensemble_model]\n",
        ")\n",
        "\n",
        "state_disagreement = experiment_runner(state_disagreement, added_noise=0.0, random_state=42)\n",
        "state_disagreement = theorist_disagreement(state_disagreement)\n",
        "\n",
        "mse_history_disagreement = []\n",
        "\n",
        "X = state_disagreement.experiment_data[iv_names].values\n",
        "y_true = state_disagreement.experiment_data[dv_names].values.ravel()\n",
        "y_pred = state_disagreement.models[0].predict(X)\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mse_history_disagreement.append(mse)\n",
        "\n",
        "print(\"Running DISAGREEMENT sampling strategy...\\n\")\n",
        "print(f\"Cycle  0/{n_cycles}: {len(state_disagreement.experiment_data):4d} samples (seed), MSE = {mse:.4f}\")\n",
        "\n",
        "for cycle in range(1, n_cycles):\n",
        "    pool_state = StandardState(\n",
        "        variables=experiment.variables,\n",
        "        conditions=pd.DataFrame(columns=iv_names),\n",
        "        experiment_data=state_disagreement.experiment_data.copy(),\n",
        "        models=state_disagreement.models\n",
        "    )\n",
        "    pool_state = pool_generator(pool_state, num_samples=20, sample_all=['participant_id'])\n",
        "    pool_state = experimentalist_disagreement(pool_state, num_samples=samples_per_cycle)\n",
        "    \n",
        "    state_disagreement.conditions = pool_state.conditions\n",
        "    state_disagreement = experiment_runner(state_disagreement, added_noise=0.0, random_state=42+cycle)\n",
        "    state_disagreement = theorist_disagreement(state_disagreement)\n",
        "    \n",
        "    X = state_disagreement.experiment_data[iv_names].values\n",
        "    y_true = state_disagreement.experiment_data[dv_names].values.ravel()\n",
        "    y_pred = state_disagreement.models[0].predict(X)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mse_history_disagreement.append(mse)\n",
        "    \n",
        "    print(f\"Cycle {cycle:2d}/{n_cycles}: {len(state_disagreement.experiment_data):4d} samples, MSE = {mse:.4f}\")\n",
        "\n",
        "print(\"\\nâœ“ Disagreement sampling complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## Part 4: Comparison Analysis\n",
        "\n",
        "Let's compare all three strategies!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-17",
      "metadata": {},
      "source": [
        "### MSE Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, n_cycles+1), mse_history_random, 'o-', \n",
        "         label='Random Sampling', linewidth=2, markersize=8, color='#ff7f0e')\n",
        "plt.plot(range(1, n_cycles+1), mse_history_uncertainty, 's-', \n",
        "         label='Uncertainty Sampling (GP)', linewidth=2, markersize=8, color='#2ca02c')\n",
        "plt.plot(range(1, n_cycles+1), mse_history_disagreement, '^-', \n",
        "         label='Disagreement Sampling (Ensemble)', linewidth=2, markersize=8, color='#d62728')\n",
        "plt.xlabel('Cycle', fontsize=12)\n",
        "plt.ylabel('Mean Squared Error', fontsize=12)\n",
        "plt.title('Active Learning Comparison: Three Strategies', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.yscale('log')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFinal Performance (MSE):\")\n",
        "print(f\"  Random:       {mse_history_random[-1]:.4f}\")\n",
        "print(f\"  Uncertainty:  {mse_history_uncertainty[-1]:.4f}\")\n",
        "print(f\"  Disagreement: {mse_history_disagreement[-1]:.4f}\")\n",
        "\n",
        "print(\"\\nImprovement vs. Random:\")\n",
        "improvement_uncertainty = (mse_history_random[-1] - mse_history_uncertainty[-1]) / mse_history_random[-1] * 100\n",
        "improvement_disagreement = (mse_history_random[-1] - mse_history_disagreement[-1]) / mse_history_random[-1] * 100\n",
        "print(f\"  Uncertainty:  {improvement_uncertainty:.1f}% better\")\n",
        "print(f\"  Disagreement: {improvement_disagreement:.1f}% better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "### Sampling Patterns Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get samples for participant 0\n",
        "participant_id = 0\n",
        "random_samples = state_random.experiment_data[\n",
        "    state_random.experiment_data['participant_id'] == participant_id\n",
        "]\n",
        "uncertainty_samples = state_uncertainty.experiment_data[\n",
        "    state_uncertainty.experiment_data['participant_id'] == participant_id\n",
        "]\n",
        "disagreement_samples = state_disagreement.experiment_data[\n",
        "    state_disagreement.experiment_data['participant_id'] == participant_id\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Random\n",
        "scatter1 = axes[0].scatter(\n",
        "    random_samples['ratio'],\n",
        "    random_samples['scatteredness'],\n",
        "    c=range(len(random_samples)),\n",
        "    cmap='viridis',\n",
        "    s=100,\n",
        "    alpha=0.6,\n",
        "    edgecolors='black',\n",
        "    linewidths=1\n",
        ")\n",
        "axes[0].set_xlabel('Ratio', fontsize=12)\n",
        "axes[0].set_ylabel('Scatteredness', fontsize=12)\n",
        "axes[0].set_title(f'Random Sampling\\n(Participant {participant_id})', fontsize=14)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xlim(-0.1, 1.1)\n",
        "axes[0].set_ylim(-0.1, 1.1)\n",
        "plt.colorbar(scatter1, ax=axes[0], label='Sample Order')\n",
        "\n",
        "# Uncertainty\n",
        "scatter2 = axes[1].scatter(\n",
        "    uncertainty_samples['ratio'],\n",
        "    uncertainty_samples['scatteredness'],\n",
        "    c=range(len(uncertainty_samples)),\n",
        "    cmap='viridis',\n",
        "    s=100,\n",
        "    alpha=0.6,\n",
        "    edgecolors='black',\n",
        "    linewidths=1\n",
        ")\n",
        "axes[1].set_xlabel('Ratio', fontsize=12)\n",
        "axes[1].set_ylabel('Scatteredness', fontsize=12)\n",
        "axes[1].set_title(f'Uncertainty Sampling\\n(Participant {participant_id})', fontsize=14)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].set_xlim(-0.1, 1.1)\n",
        "axes[1].set_ylim(-0.1, 1.1)\n",
        "plt.colorbar(scatter2, ax=axes[1], label='Sample Order')\n",
        "\n",
        "# Disagreement\n",
        "scatter3 = axes[2].scatter(\n",
        "    disagreement_samples['ratio'],\n",
        "    disagreement_samples['scatteredness'],\n",
        "    c=range(len(disagreement_samples)),\n",
        "    cmap='viridis',\n",
        "    s=100,\n",
        "    alpha=0.6,\n",
        "    edgecolors='black',\n",
        "    linewidths=1\n",
        ")\n",
        "axes[2].set_xlabel('Ratio', fontsize=12)\n",
        "axes[2].set_ylabel('Scatteredness', fontsize=12)\n",
        "axes[2].set_title(f'Disagreement Sampling\\n(Participant {participant_id})', fontsize=14)\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "axes[2].set_xlim(-0.1, 1.1)\n",
        "axes[2].set_ylim(-0.1, 1.1)\n",
        "plt.colorbar(scatter3, ax=axes[2], label='Sample Order')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nSample Counts:\")\n",
        "print(f\"  Random:       {len(random_samples)}\")\n",
        "print(f\"  Uncertainty:  {len(uncertainty_samples)}\")\n",
        "print(f\"  Disagreement: {len(disagreement_samples)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {},
      "source": [
        "### Disagreement vs. Uncertainty Maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test grid\n",
        "ratio_range = np.linspace(0, 1, 30)\n",
        "scatter_range = np.linspace(0, 1, 30)\n",
        "ratio_grid, scatter_grid = np.meshgrid(ratio_range, scatter_range)\n",
        "X_grid = np.c_[\n",
        "    np.full(ratio_grid.size, participant_id),\n",
        "    ratio_grid.ravel(),\n",
        "    scatter_grid.ravel()\n",
        "]\n",
        "\n",
        "# Get uncertainty/disagreement estimates\n",
        "_, std_uncertainty = state_uncertainty.models[0].predict(X_grid, return_std=True)\n",
        "_, std_disagreement = state_disagreement.models[0].predict(X_grid, return_std=True)\n",
        "\n",
        "std_uncertainty_grid = std_uncertainty.reshape(ratio_grid.shape)\n",
        "std_disagreement_grid = std_disagreement.reshape(ratio_grid.shape)\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Uncertainty\n",
        "im1 = axes[0].contourf(ratio_grid, scatter_grid, std_uncertainty_grid, levels=20, cmap='YlOrRd')\n",
        "axes[0].scatter(uncertainty_samples['ratio'], uncertainty_samples['scatteredness'],\n",
        "                c='blue', s=50, alpha=0.7, edgecolors='black', linewidths=1, label='Sampled Points')\n",
        "axes[0].set_xlabel('Ratio', fontsize=12)\n",
        "axes[0].set_ylabel('Scatteredness', fontsize=12)\n",
        "axes[0].set_title('Uncertainty Map (GP)', fontsize=14)\n",
        "axes[0].legend()\n",
        "plt.colorbar(im1, ax=axes[0], label='Prediction Std Dev')\n",
        "\n",
        "# Disagreement\n",
        "im2 = axes[1].contourf(ratio_grid, scatter_grid, std_disagreement_grid, levels=20, cmap='YlOrRd')\n",
        "axes[1].scatter(disagreement_samples['ratio'], disagreement_samples['scatteredness'],\n",
        "                c='blue', s=50, alpha=0.7, edgecolors='black', linewidths=1, label='Sampled Points')\n",
        "axes[1].set_xlabel('Ratio', fontsize=12)\n",
        "axes[1].set_ylabel('Scatteredness', fontsize=12)\n",
        "axes[1].set_title('Disagreement Map (Ensemble)', fontsize=14)\n",
        "axes[1].legend()\n",
        "plt.colorbar(im2, ax=axes[1], label='Ensemble Std Dev')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Differences:\")\n",
        "print(\"  - GP uncertainty: Smooth, distance-based (RBF kernel)\")\n",
        "print(\"  - Ensemble disagreement: Data-driven, captures model uncertainty\")\n",
        "print(\"  - Both capture epistemic uncertainty, but from different perspectives\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {},
      "source": [
        "## Part 5: When to Use Each Strategy?\n",
        "\n",
        "Let's summarize the trade-offs:\n",
        "\n",
        "| Strategy | Pros | Cons | Best For |\n",
        "|----------|------|------|----------|\n",
        "| **Random** | Simple, no overhead | Inefficient, wastes samples | Baselines, very small budgets |\n",
        "| **Uncertainty (GP)** | Well-calibrated, smooth | Assumes kernel structure, slow for large data | Smooth functions, medium data |\n",
        "| **Disagreement (Ensemble)** | Robust, flexible | Computationally expensive, needs multiple models | Complex functions, large budgets |\n",
        "\n",
        "### Practical Recommendations\n",
        "\n",
        "1. **Start with Uncertainty (GP)** if:\n",
        "   - Your function is relatively smooth\n",
        "   - You have moderate sample budget (100-1000 samples)\n",
        "   - You want well-calibrated uncertainty estimates\n",
        "\n",
        "2. **Use Disagreement (Ensemble)** if:\n",
        "   - Your function is highly non-linear or discontinuous\n",
        "   - You have large computational budget\n",
        "   - You want robustness to model misspecification\n",
        "\n",
        "3. **Hybrid Approaches**:\n",
        "   - Early cycles: Random (exploration)\n",
        "   - Mid cycles: Uncertainty (efficient sampling)\n",
        "   - Late cycles: Disagreement (refining complex regions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-24",
      "metadata": {},
      "source": [
        "## Summary & Key Takeaways\n",
        "\n",
        "You've learned:\n",
        "\n",
        "1. âœ… **Ensemble Models**: Building committees for disagreement estimation\n",
        "2. âœ… **Disagreement Sampling**: Query where models disagree most\n",
        "3. âœ… **AutoRA Implementation**: Using `inequality_sample` with ensemble models\n",
        "4. âœ… **Uncertainty vs. Disagreement**: When to use each approach\n",
        "5. âœ… **Performance Comparison**: Both outperform random sampling significantly\n",
        "6. âœ… **Practical Guidelines**: Choosing the right strategy for your problem\n",
        "\n",
        "### The Complete Active Learning Toolkit\n",
        "\n",
        "You now have three powerful strategies:\n",
        "- **Grid/Factorial**: Uniform coverage (Tutorial 1)\n",
        "- **Uncertainty**: Model-driven intelligent sampling (Tutorial 2)\n",
        "- **Disagreement**: Robust ensemble-based sampling (Tutorial 3)\n",
        "\n",
        "### Group Project Connection\n",
        "\n",
        "For your group project, you can:\n",
        "1. Implement any of these strategies (or combine them!)\n",
        "2. Compare performance on the 2AFC experiment\n",
        "3. Test robustness to different noise levels\n",
        "4. Explore your own experimentalist ideas!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-25",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "1. **Ensemble Size**: Vary `n_models` (3, 5, 10, 20). How does ensemble size affect:\n",
        "   - Model performance?\n",
        "   - Computational cost?\n",
        "   - Disagreement estimates?\n",
        "\n",
        "2. **Hybrid Strategy**: Implement a hybrid experimentalist that:\n",
        "   - Uses random sampling for first 2 cycles\n",
        "   - Uses uncertainty for cycles 3-7\n",
        "   - Uses disagreement for cycles 8-10\n",
        "   \n",
        "3. **Bootstrap Ensembles**: Modify `FFNEnsemble` to train each model on a bootstrap sample (random subset with replacement) instead of the full dataset. Does this improve diversity?\n",
        "\n",
        "4. **Noise Robustness**: Add noise to observations (`added_noise=0.1, 0.5`). Which strategy is most robust?\n",
        "\n",
        "5. **Calibration Analysis**: For both uncertainty and disagreement, compute:\n",
        "   - Coverage: How often does true value fall within predicted interval?\n",
        "   - Calibration: Plot predicted std vs. actual error\n",
        "\n",
        "6. **Custom Experimentalist**: Implement your own experimentalist that combines:\n",
        "   - Uncertainty estimates\n",
        "   - Disagreement estimates\n",
        "   - Distance from previous samples\n",
        "   Create a weighted score and select based on that!\n",
        "\n",
        "7. **Active Learning Literature**: Read Settles (2009) survey and implement another query strategy:\n",
        "   - Query-by-bagging\n",
        "   - Variance reduction\n",
        "   - Expected model change"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-26",
      "metadata": {},
      "source": [
        "## Congratulations!\n",
        "\n",
        "You've completed the **Advanced Active Learning** tutorial! You now have a complete toolkit for intelligent experimental design using AutoRA.\n",
        "\n",
        "You're ready to tackle the group project and apply these methods to optimize experiments in cognitive science!\n",
        "\n",
        "### Final Thoughts\n",
        "\n",
        "Active learning is not just about algorithms - it's about:\n",
        "- **Efficiency**: Making every observation count\n",
        "- **Science**: Asking the right questions at the right time\n",
        "- **Discovery**: Uncovering patterns faster than traditional methods\n",
        "\n",
        "Good luck with your projects! ðŸš€"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
