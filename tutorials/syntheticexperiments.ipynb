{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to synthetic experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the concept of synthetic experiments and demonstrates how to implement one using Python. \n",
    "\n",
    "Synthetic experiments are a powerful tool for studying the relationship between independent variables (factors) and dependent variables (observations) in an controlled environment. They allow us to generate data that resembles real-world data but is not as complex as data collected in the real world while being also free from the limitations, costs and biases that can arise from collecting data in the real world. \n",
    "\n",
    "This way, the later introduced concepts and algorithms from the 'Optimizing Experimental Design' course can be implemented, tested and validated easily. \n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Define a ground truth function that represents the true relationship between the independent and dependent variables.\n",
    "- Generate noisy data by adding noise to the true function values.\n",
    "- Define treatments and experimental units which will serve as the base for collecting data\n",
    "- Generating a dataset by defining a sample size, different treatments and eventually collecting samples.\n",
    "- Run a model recovery to fit a model to the collected data and recover the parameters of the ground truth function.\n",
    "- Get a feeling for the recovered model quality in dependence of the sample size and noise level\n",
    "\n",
    "You will also explore how to experiment with different noise levels, sample sizes, and conditions to see how they affect the results of the model recovery.\n",
    "\n",
    "By the end of this tutorial, you will have a strong understanding of how to implement and analyze synthetic experiments using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the relevant libraries and package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from typing import Callable, Iterable\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will implement a ground truth which will serve us later to generate the observations.\n",
    "\n",
    "In this section, you will learn to:\n",
    "- Implement the ground truth method that models the relationship between the independent variables (factors) and the dependent variable (observation).\n",
    "- Implement a method that generates noise and add it to the output of the ground truth\n",
    "- Implement a class, whose instances will resemble the experimental units (e.g. participants)\n",
    "- Create experimental units given sets of parameters and generate first observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a ground truth\n",
    "\n",
    "The ground truth can be any mathematical expression that takes in the independent variables as arguments and returns the dependent variable.\n",
    "\n",
    "In our case, we will model a 2-factor ground truth with the two factors 'x' and 'y' and their respective parameters.\n",
    "\n",
    "Replace the variable 'dependent_variable' which is currently 'None' with the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(x, y, parameters=np.ones(2,)):\n",
    "    \n",
    "    dependent_variable = None\n",
    "    # add your code here:\n",
    "    \n",
    "    return dependent_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your ground truth by giving it random values and check if it has the desired properties.\n",
    "\n",
    "Replace now the None-values with your own factor levels and parameters.\n",
    "\n",
    "This code takes in the defined values for x, y and the parameters and outputs a 3D-plot of the observation over the given conditions.\n",
    "\n",
    "Leave the code after defining the necessary value untouched so you get the 3D-plot.\n",
    "\n",
    "Example:\n",
    "\n",
    "```x = np.arange(1, 10)```\n",
    "\n",
    "```y = np.arange(1, 10)```\n",
    "\n",
    "```parameters = [1, 2]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the factor levels\n",
    "# you can use numpy arrays, lists or tuples\n",
    "x = np.arange(0,10)\n",
    "y = np.arange(0,10)\n",
    "parameters = [2, 3]\n",
    "\n",
    "# PLEASE DO NOT TOUCH THE CODE FROM HERE!\n",
    "\n",
    "# set a sample size\n",
    "sample_size = len(x)\n",
    "\n",
    "# initiate the z array\n",
    "z = np.zeros((sample_size, sample_size))\n",
    "\n",
    "# collect the observations\n",
    "x, y = np.meshgrid(x, y)\n",
    "for i in range(sample_size):\n",
    "    z[i, :] = ground_truth(x[i], y[i], parameters)\n",
    "\n",
    "# make a surface plot to visualize the ground_truth\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.plot_surface(x, y, z, cmap=cm.Blues)\n",
    "ax.set_title('Ground truth: Observations over factor levels')\n",
    "ax.set_xlabel('Factor x')\n",
    "ax.set_ylabel('Factor y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it look good? Well, then let's move to the next part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a noise signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise signal is a value drawn from a normal distribution. \n",
    "\n",
    "It will be multiplied by a specified noise level and later be added to the dependent variable to get the final observation.\n",
    "\n",
    "The scale of normal distribution should be $0.1$\n",
    "\n",
    "This way we get the inherent noise, which basically any experiment comes with.\n",
    "\n",
    "Tip: numpy comes already with a method that draws values from a random distribution. Use that one! Call it with np.random.normal(mean, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(noise_level):\n",
    "    \n",
    "    noise = None\n",
    "    # add your code here:\n",
    "    \n",
    "    # draw a value from a normal distribution\n",
    "    \n",
    "    # multiply it with the noise_level before returning it. \n",
    "    # This way we will later have control over the noise magnitude without changing the code.\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the noise looks as we expect it to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 1\n",
    "\n",
    "noise_sample_size = 100\n",
    "noise_samples = np.zeros(noise_sample_size)\n",
    "\n",
    "for i in range(noise_sample_size):\n",
    "    noise_samples[i] = noise(noise_level=1)\n",
    "    \n",
    "plt.plot(noise_samples, '.')\n",
    "plt.title('Collected noise samples')\n",
    "plt.ylabel('Noise')\n",
    "plt.xlabel('Sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some noise to the observations and compare the previous observations without noise with the current noisy ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set noise level\n",
    "noise_level = 3\n",
    "\n",
    "# initiate the noisy z array\n",
    "z_noisy = np.zeros((sample_size, sample_size))\n",
    "\n",
    "# collect the observations\n",
    "for i in range(sample_size):\n",
    "    z_noisy[i, :] = ground_truth(x[i], y[i], parameters)\n",
    "    \n",
    "# add noise\n",
    "for i in range(z_noisy.shape[0]):\n",
    "    for j in range(z_noisy.shape[1]):\n",
    "        z_noisy[i, j] += noise(noise_level)\n",
    "\n",
    "# make a surface plot to visualize the ground_truth\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.plot_surface(x, y, z, cmap=cm.Blues)\n",
    "ax.set_title('Unnoisy observations over factor levels')\n",
    "ax.set_xlabel('Factor x')\n",
    "ax.set_ylabel('Factor y')\n",
    "plt.show()\n",
    "\n",
    "# make a surface plot to visualize the ground_truth\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.plot_surface(x, y, z_noisy, cmap=cm.Blues)\n",
    "ax.set_title('Noisy observations over factor levels')\n",
    "ax.set_xlabel('Factor x')\n",
    "ax.set_ylabel('Factor y')\n",
    "plt.show()\n",
    "\n",
    "# make a plot of the difference between the unnoisy and the noisy signal\n",
    "z_error = np.abs(z - z_noisy)\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.plot_surface(x, y, z_error, cmap=cm.Reds)\n",
    "ax.set_title('Error between unnoisy and noisy observations over factor levels')\n",
    "ax.set_xlabel('Factor x')\n",
    "ax.set_ylabel('Factor y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does your noise function look good? If so, great! Let's go to the next section then!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing an experimental unit class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will implement a class for experimental units.\n",
    "\n",
    "In the psychological context, experimental units refer to individual participants or groups of participants which get the same treatment.\n",
    "\n",
    "These participants are similar in terms of the basic cognitive functions which are used to solve a problem but may differ in e.g. skill.\n",
    "\n",
    "To account for these differences between participants, we will now implement a class which takes in:\n",
    "- a problem_solver method which refers to the ground_truth method, you already implemented.\n",
    "- a noise method which you already implemented as well.\n",
    "- a parameter set, to account for the differences inbetween the participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experimental_unit:\n",
    "    \n",
    "    def __init__(self,\n",
    "        problem_solver: Callable, \n",
    "        noise: Callable, \n",
    "        parameters: Iterable, \n",
    "        noise_level: float = 1,\n",
    "        ):\n",
    "        \n",
    "        self.problem_solver_fun = problem_solver\n",
    "        self.noise_fun = noise\n",
    "        self.parameters = parameters\n",
    "        self.noise_level = noise_level\n",
    "        \n",
    "    def problem_solver(self, x, y):\n",
    "        # this method returns the dependent variable based on the independent variables x and y and the parameters\n",
    "        return self.problem_solver_fun(x, y, self.parameters)\n",
    "    \n",
    "    def noise(self, noise_level=None):\n",
    "        # this method returns the noise\n",
    "        if noise_level == None:\n",
    "            noise_level = self.noise_level\n",
    "            \n",
    "        return self.noise_fun(noise_level)\n",
    "    \n",
    "    def step(self, x, y, noise=True):\n",
    "        # this method returns the observation which is the sum of the dependent variable and the noise\n",
    "        if noise:\n",
    "            return self.problem_solver(x, y) + self.noise()\n",
    "        else:\n",
    "            return self.problem_solver(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two instances (individual participants) of the the 'experimental unit' class with different parameters and compare the collected observations.\n",
    "\n",
    "In the first step we won't add any noise so we get a feeling on how parameters influence the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace None with your own treatment combinations\n",
    "parameters_participant1 = None\n",
    "parameters_participant2 = None\n",
    "\n",
    "# Create two experimental units with different parameters\n",
    "participant1 = experimental_unit(\n",
    "    problem_solver=ground_truth,\n",
    "    noise=noise,\n",
    "    parameters=parameters_participant1,\n",
    "    noise_level=0,\n",
    ")\n",
    "\n",
    "participant2 = experimental_unit(\n",
    "    problem_solver=ground_truth,\n",
    "    noise=noise,\n",
    "    parameters=parameters_participant2,\n",
    "    noise_level=0,\n",
    ")\n",
    "\n",
    "# collect the observations for each participant\n",
    "# add your code here (you can take the relevant code pieces from above):\n",
    "\n",
    "# plot the observations for each participant in a surface plot\n",
    "# add your code here (you can take the relevant code pieces from above):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take all these methods and classes, which we previously implemented to create a dataset.\n",
    "\n",
    "This dataset will have unit-to-unit variation and also trial-to-trial variation thanks to the implemented noise and the experimental_unit class, which takes different sets of parameters to define one unit.\n",
    "\n",
    "In this section you will learn to:\n",
    "- Define the relevant dataset parameters (number units, number trials per unit)\n",
    "- Define arbitrary parameter sets\n",
    "- Create a collection of experimental units based on these parameter sets\n",
    "- Perform runs and collect the data in the form of the collection (factors, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to define the parameters of our dataset.\n",
    "This contains the extrinsic parameters over which we have full control: \n",
    "- the number of units we are going to observe\n",
    "- the number of conditions each unit will be tested on\n",
    "- the number of repetitions per conditions\n",
    "\n",
    "And the intrinsic parameter for the noise level (over this parameter we usually do not have any control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset parameters\n",
    "\n",
    "# number of experimental units\n",
    "n_units = 10\n",
    "\n",
    "# number of observations per experimental unit\n",
    "n_conditions = 10\n",
    "\n",
    "# number of repetitions per condition\n",
    "n_repetitions = 10\n",
    "\n",
    "# amount of noise, we are going to add to the data\n",
    "noise_level = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the unit parameters and the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create n_units arbitrary parameter sets to define n_units experimental units\n",
    "# we will draw the parameters from a uniform distribution between 1 and 3\n",
    "parameters = np.random.uniform(1, 3, (n_units, 2))\n",
    "\n",
    "# create n_trials conditions which will be taken for all experimental units\n",
    "# we will draw the conditions from a uniform distribution between 0 and 10\n",
    "conditions = np.random.uniform(0, 10, (n_conditions, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the parameters, we can now create instances of our experimental units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of experimental units\n",
    "unit = []\n",
    "\n",
    "# create the experimental units\n",
    "for i in range(n_units):\n",
    "    unit.append(\n",
    "        experimental_unit(\n",
    "            problem_solver=ground_truth,\n",
    "            noise=noise,\n",
    "            parameters=parameters[i],\n",
    "            noise_level=noise_level,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get to the part where we are creating the actual dataset.\n",
    "\n",
    "This involves:\n",
    "- going with each unit through all the conditions\n",
    "- collecting the trial-to-trial data\n",
    "- collecting the unit data\n",
    "\n",
    "This way, we will have a 3D-Corpus of the data with the dimensions (experimental unit, condition, repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array which will be the dataset\n",
    "dataset = np.zeros((n_units, n_conditions, n_repetitions))\n",
    "\n",
    "for i in range(n_units):\n",
    "    # here we collect the observations for each experimental unit\n",
    "    for j in range(n_conditions):\n",
    "        # here we collect the observations for each condition for each experimental unit\n",
    "        for k in range(n_repetitions):\n",
    "            # here we collect the observations for each repetition for each condition for each experimental unit\n",
    "            dataset[i, j, k] = unit[i].step(conditions[j, 0], conditions[j, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the dataset a little bit\n",
    "\n",
    "We will compute: \n",
    "- the mean and standard deviation (std) for each experimental unit for all conditions and repitions -> 2D arrays (n_units, n_conditions)\n",
    "- the mean and std for each condition across all experimental units and repitions -> 2D arrays (n_conditions, n_conditions)\n",
    "\n",
    "We will make:\n",
    "- an errorbar plot for the unit-wise mean and std for one condition to show how the observations of one condition can differ from unit to unit \n",
    "- a 2D Hist for the condition-wise std across all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index for the condition which will be observed\n",
    "condition_index = 0\n",
    "\n",
    "# compute the mean and std for each unit and condition\n",
    "unit_mean = np.mean(dataset, axis=2)\n",
    "unit_std = np.std(dataset, axis=2)\n",
    "\n",
    "# compute the mean and std for each condition\n",
    "condition_mean = np.mean(dataset, axis=2)\n",
    "condition_std = np.std(condition_mean, axis=0)\n",
    "\n",
    "# plot an errorbar plot to visualize the unit means and stds for the selected condition\n",
    "plt.errorbar(\n",
    "    np.arange(n_units),\n",
    "    unit_mean[:, condition_index],\n",
    "    yerr=unit_std[:, condition_index],\n",
    "    fmt='o',\n",
    ")\n",
    "plt.title('Unit means and stds for condition {}'.format(condition_index))\n",
    "plt.xlabel('Unit')\n",
    "plt.ylabel('Mean')\n",
    "plt.show()\n",
    "\n",
    "# visualize the condition stds across all experimental units over the conditions\n",
    "plt.bar(\n",
    "    np.arange(n_conditions),\n",
    "    condition_std,\n",
    ")\n",
    "plt.title('Condition stds across all experimental units')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Std')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you expect the std to change for an increased amount of trials and/or noise?\n",
    "\n",
    "Test your assumption by changing the value for the amount of trials and/or noise an re-run the code of this section!\n",
    "\n",
    "What did you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameter recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will take the previously generated dataset to fit a regression model from the ```sklearn``` package.\n",
    "\n",
    "Here you will learn to:\n",
    "- Prepare data for model fitting\n",
    "- Use data to fit a model\n",
    "- Get a feeling for the significance of noise and sample size on the quality of the recovered model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first we need to prepare the data for the further steps.\n",
    "\n",
    "This will be done by:\n",
    "1. Creating a 2D observations matrix of the shape `(samples, features)`\n",
    "1. Creating a 2D conditions matrix of the length of the data matrix of the shape `(samples, features)`\n",
    "1. Concatenating the observations and the conditions along the `features` axis\n",
    "1. Shuffling along the the `samples` axis to break up any correlations other than condition-observation\n",
    "1. Splitting the data into training and test data\n",
    "    - Training data is used for fitting the model\n",
    "    - Test data is used for evaluating the model's generalization capability and making sure it did not simply learn the samples (i.e. overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a matrix\n",
    "conditions_recovery = conditions.repeat(n_repetitions, axis=0)  # repeat the single conditions as they have been presented to each unit n_repetitions times\n",
    "conditions_recovery = np.stack([conditions_recovery] * n_units, axis=0)  # stack the conditions for each unit\n",
    "conditions_recovery = conditions_recovery.reshape(-1, 2)  # flatten the conditions to create a 2D matrix. The first axis is n_units * n_conditions * n_repetitions and the second axis is len(conditions)\n",
    "observations_recovery = dataset.flatten().reshape(-1, 1)  # flatten (shape -> (-1,)) and reshape (shape -> (-1, len(response)))) the responses to create a 2D vector. The first axis is n_units * n_conditions * n_repetitions and the second axis is len(response)\n",
    "\n",
    "# Concatenate the conditions and the observations\n",
    "data_recovery = np.concatenate((conditions_recovery, observations_recovery), axis=1)\n",
    "\n",
    "# Shuffle the data\n",
    "np.random.shuffle(data_recovery)\n",
    "\n",
    "# Split the data into train and test data\n",
    "train_ratio = 0.8  # define the amount of data which will be used for training\n",
    "train_data = data_recovery[:int(len(data_recovery) * train_ratio)]  # take the first train_ratio*100% of the data for training\n",
    "test_data = data_recovery[int(len(data_recovery) * train_ratio):]  # take the remaining data for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to implement the model fitting algorithm.\n",
    "\n",
    "To do that, we will use a simple linear regression estimator from the sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(train_data[:, :conditions_recovery.shape[-1]], train_data[:, conditions_recovery.shape[-1]:])\n",
    "\n",
    "# Recovered parameters\n",
    "recovered_a = model.coef_[0, 0]\n",
    "recovered_b = model.coef_[0, 1]\n",
    "\n",
    "# print the recovered parameters\n",
    "a_true = np.round(np.mean(parameters[:, 0]), 3)\n",
    "b_true = np.round(np.mean(parameters[:, 1]), 3)\n",
    "print('After running experiments on {} units with {} conditions and {} repetitions per condition, we recovered the following parameters:'.format(n_units, n_conditions, n_repetitions))\n",
    "print('True parameters (mean across all units): a = {}, b = {}'.format(a_true, b_true))\n",
    "print('Recovered parameters: a = {}, b = {}'.format(np.round(recovered_a, 3), np.round(recovered_b, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to test the fitted model with the test data.\n",
    "We will compute the prediction accuracy with a sklearn metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# use the fitted model to predict the test observations\n",
    "observations_predicted = model.predict(test_data[:, :conditions_recovery.shape[-1]])\n",
    "\n",
    "# compute the means of the two datasets\n",
    "original_mean = np.mean(test_data[:, conditions_recovery.shape[-1]:]) \n",
    "recovered_mean = np.mean(observations_predicted)\n",
    "\n",
    "# compute prediciton error\n",
    "prediction_accuracy = mean_squared_error(test_data[:, conditions_recovery.shape[-1]:], observations_predicted)\n",
    "print('Mean absolute error: {}'.format(prediction_accuracy))\n",
    "\n",
    "# compare the means\n",
    "print('Original mean: {}'.format(original_mean))\n",
    "print('Recovered mean: {}'.format(recovered_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the result on the test data look like?\n",
    "\n",
    "A small error - compared to the average amplitude of the observation - is acceptable since it's difficult to get a perfect match. For most cases it's even impossible.\n",
    "\n",
    "Get a feeling for the significance of noise and sample size on the quality of a fitted model and its predictive power by adjusting the number of units, conditions, repitions and also the noise level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You finished the first tutorial.\n",
    "\n",
    "Now you should have a good idea about:\n",
    "- How to implement a synthetic experiment\n",
    "- How to get unit-to-unit and trial-to-trial variation into your dataset\n",
    "- How the sample size and noise affects the recovery of parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
