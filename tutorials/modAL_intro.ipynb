{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using modAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is based on the official documentation. For more information click [here](https://modal-python.readthedocs.io/en/latest/content/overview/modAL-in-a-nutshell.html) to get to the official website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is about introducing you to the concept of active learning through first steps with the *modAL* package.\n",
    "\n",
    "Here you will learn to:\n",
    "- write a simple active learning sampling strategy\n",
    "- utilize the defined sampling strategy as part of the *modAL* package\n",
    "\n",
    "**modAL** is an active learning framework for Python3, designed with modularity, flexibility and extensibility in mind. Built on top of scikit-learn, it allows you to rapidly create active learning workflows with nearly complete freedom. What is more, you can easily replace parts with your custom built solutions, allowing you to design novel algorithms with ease.\n",
    "\n",
    "With the recent explosion of available data, you have can have millions of unlabelled examples with a high cost to obtain labels. For instance, when trying to predict the sentiment of tweets, obtaining a training set can require immense manual labour. But worry not, active learning comes to the rescue! In general, AL is a framework allowing you to increase classification performance by intelligently querying you to label the most informative instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install modAL you can use this command which will install the package directly from source:\n",
    "\n",
    "`%pip install git+https://github.com/modAL-python/modAL.git`\n",
    "\n",
    "(Remove `%` if you are running this command from your terminal or from a .py-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/modAL-python/modAL.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modAL in action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active learning with a scikit-learn classifier, for instance RandomForestClassifier, can be as simple as the following.\n",
    "\n",
    "```\n",
    "from modAL.models import ActiveLearner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initializing the learner\n",
    "learner = ActiveLearner(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    X_training=X_training, y_training=y_training\n",
    ")\n",
    "\n",
    "# query for labels\n",
    "query_idx, query_inst = learner.query(X_pool)\n",
    "\n",
    "# ...obtaining new labels from the Oracle...\n",
    "\n",
    "# supply label for queried instance\n",
    "learner.teach(X_pool[query_idx], y_new)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example with active regression\n",
    "\n",
    "To see modAL in real action, letâ€™s consider an active regression problem with Gaussian processes! In this example, we shall try to learn a noisy sine function.\n",
    "\n",
    "Let's define our dataset with the inputs `X` and the outputs `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# training data\n",
    "x_training = np.random.choice(np.linspace(0, 20, 10000), size=200, replace=False).reshape(-1, 1)\n",
    "ground_truth = lambda x: np.sin(x) + np.random.normal(scale=0.3, size=x.shape)\n",
    "y_training = ground_truth(x_training)\n",
    "\n",
    "# test data\n",
    "x_test = np.linspace(0, 20, 1000)\n",
    "y_test = ground_truth(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x_training, y_training, c='k', s=20)\n",
    "plt.title('sin(x) + noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For active learning, we shall define a custom query strategy tailored to Gaussian processes. In a nutshell, a *query stategy* in modAL is a function taking (at least) two arguments (an estimator object and a pool of examples), outputting the index of the queried instance and the instance itself. In our case, the arguments are `regressor` and `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_regression_std(regressor, x, n_instances=1):\n",
    "    _, std = regressor.predict(x, return_std=True)  # for a Gaussian process estimator, we get the standard deviation easily\n",
    "    # get the n_instances indices with the highest standard deviation\n",
    "    query_idx = np.argsort(std)[-n_instances:]    \n",
    "    return query_idx, x[query_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up the query strategy and the data, the active learner can be initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF\n",
    "\n",
    "n_initial = 5  # initial amount of random samples\n",
    "\n",
    "# get initial training data - random samples\n",
    "initial_idx = np.random.choice(range(len(x_training)), size=n_initial, replace=False)  # draw random initial indices\n",
    "x_training_init, y_training_init = x_training[initial_idx], y_training[initial_idx]  # set the initial training data\n",
    "\n",
    "# define a kernel for the Gaussian process regressor\n",
    "kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "         + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "\n",
    "# initialize the regressor and train it with the initial training data\n",
    "regressor = ActiveLearner(\n",
    "    estimator=GaussianProcessRegressor(kernel=kernel),\n",
    "    query_strategy=GP_regression_std,\n",
    "    X_training=x_training_init.reshape(-1, 1), y_training=y_training_init.reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how well the estimator is fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred, y_std = regressor.predict(x_test.reshape(-1, 1), return_std=True)\n",
    "y_pred, y_std = y_pred.ravel(), y_std.ravel()\n",
    "\n",
    "# compute the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# plotting method which we can reuse later\n",
    "def plotting_method(x1, y1, y1_std, x_true=None, y_true=None, mse=None, x_new=None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x1, y1, label='Prediction')\n",
    "    plt.fill_between(x1, y1 - y1_std, y1 + y1_std, alpha=0.2)\n",
    "    if x_true is not None and y_true is not None:\n",
    "        plt.scatter(x_true, y_true, c='grey', s=20, label='Training samples')\n",
    "    if x_new is not None:\n",
    "        # make a vertical line to indicate the new training sample\n",
    "        if isinstance(x_new, (int, float)):\n",
    "            x_new = [x_new]\n",
    "        for x in x_new:\n",
    "            plt.axvline(x=x, c='r', linestyle='--', label='New query')\n",
    "    if mse is not None:\n",
    "        plt.title(f'Prediction over the whole grid (mse={np.round(mse, 4)})')\n",
    "    else:\n",
    "        plt.title('Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotting_method(x_test, y_pred, y_std, x_true=x_training, y_true=y_training, mse=mse, x_new=x_training_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue band enveloping the regressor represents the standard deviation of the Gaussian process at the given point. \n",
    "\n",
    "Now we are ready to do active learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_queries = 1\n",
    "\n",
    "query_idx, query_instances = regressor.query(x_training, n_instances=n_queries)  # get the query points from the regressor which are expected to be the most informative\n",
    "regressor.teach(x_training[query_idx].reshape(-1, 1), y_training[query_idx].reshape(-1, 1))  # fit the model with the query points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the regressor benefited from the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicted response and the standard deviation\n",
    "y_pred, y_std = regressor.predict(x_test.reshape(-1, 1), return_std=True)\n",
    "y_pred, y_std = y_pred.ravel(), y_std.ravel()\n",
    "\n",
    "# compute the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "plotting_method(x_test, y_pred, y_std, x_true=x_training, y_true=y_training, mse=mse, x_new=x_training[query_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it look already any better?\n",
    "\n",
    "What happened from the initial plot to the second one?\n",
    "\n",
    "Let's iterate a few more times and check the result after each iteration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "\n",
    "for _ in range(iterations):\n",
    "    query_idx, query_instance = regressor.query(x_training, n_instances=n_queries)  # get the query points from the regressor which are expected to be the most informative\n",
    "    regressor.teach(x_training[query_idx].reshape(-1, 1), y_training[query_idx].reshape(-1, 1))  # fit the model with the query points\n",
    "    \n",
    "    # get the predicted response and the standard deviation\n",
    "    y_pred, y_std = regressor.predict(x_test.reshape(-1, 1), return_std=True)\n",
    "    # y_pred, y_std = y_pred.ravel(), y_std.ravel()\n",
    "\n",
    "    # compute the mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    plotting_method(x_test, y_pred, y_std, x_true=x_training, y_true=y_training, mse=mse, x_new=x_training[query_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this with a random sampling method\n",
    "\n",
    "Now we implement a simple random sampling method and give it directly the amount of training samples which we gave the active learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_random_points = n_initial + (1+iterations)*n_queries\n",
    "\n",
    "# get a training set of random points and evaluate the regression\n",
    "idx = np.random.randint(0, len(x_training), size=n_random_points)\n",
    "x_training_random = x_training[idx]\n",
    "y_training_random = ground_truth(x_training_random)\n",
    "\n",
    "regressor_rnd = GaussianProcessRegressor(kernel=kernel)  # initialize the same regressor as for the active learner\n",
    "regressor_rnd.fit(x_training_random.reshape(-1, 1), y_training_random.reshape(-1, 1))  # fit the regressor to the random data\n",
    "regressor_rnd_pred, regressor_rnd_std = regressor_rnd.predict(x_test.reshape(-1, 1), return_std=True)  # get the predicted response and the standard deviation\n",
    "regressor_rnd_pred, regressor_rnd_std = regressor_rnd_pred.ravel(), regressor_rnd_std.ravel()\n",
    "\n",
    "# compute the mean squared error\n",
    "mse = mean_squared_error(y_test, regressor_rnd_pred)\n",
    "\n",
    "plotting_method(x_test, regressor_rnd_pred, regressor_rnd_std, x_true=x_training, y_true=y_training, mse=mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the estimator with random sampling perform compared to active learning?\n",
    "\n",
    "Can you explain the results by looking step-by-step at the chosen samples by the active learning algorithm?\n",
    "\n",
    "Try and increase the noise bit-by-bit e.g., in steps of 0.2 and re-run the code.\n",
    "\n",
    "What happens hereby?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You've finished the introductory tutorial to active learning and the key components of modAL!\n",
    "\n",
    "Let's explore the key features of modAL even more in the next tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
