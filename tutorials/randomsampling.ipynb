{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Random Sampling Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will learn about different random sampling strategies and in which cases they are useful.\n",
    "\n",
    "This notebook covers the following strategies:\n",
    "- sampling from a normal distribution\n",
    "- sampling from a uniform distribution\n",
    "- sampling with a latin hypercube\n",
    "\n",
    "You will explore the generated treatment combinations and compare them visually.\n",
    "\n",
    "You are also going to scale the gathered treatments to a certain value range to keep the differently collected treatments as comparable as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we set the general parameters and methods which will be used at each stage of this notebook.\n",
    "\n",
    "The parameters in this case are:\n",
    "- the sample size\n",
    "- the number of factors.\n",
    "- the value range for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 100\n",
    "n_factors = 2\n",
    "range = (-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Before gathering the different treatments, we will implement a scaling method.\n",
    "\n",
    "This scaling method will scale the gathered treatments to a given range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, range):\n",
    "    \"\"\"\n",
    "    Scale the input to the given range.\n",
    "    Args:\n",
    "        x: the input to scale. Can be any type that can be converted to a numpy array.\n",
    "        range: the range to scale to. Must be a tuple of length 2, with the first element being the minimum and the second element being the maximum.\n",
    "    \"\"\"\n",
    "    assert len(range) == 2, \"range must be a tuple of length 2.\"\n",
    "    \n",
    "    # add your code here\n",
    "    # Tip: normalize the array first, then scale it to the range\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work properly? Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "array = scale(array, range)\n",
    "\n",
    "assert np.min(array) == range[0], f\"Minimum of scaled array is not equal to minimum of range.\\nThe scaled array is {array}.\"\n",
    "assert np.max(array) == range[1], f\"Maximum of scaled array is not equal to maximum of range.\\nThe scaled array is {array}.\"\n",
    "print(f\"Well done! Looks like your scaling method works as expected!\\nThe scaled array is {array}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from a normal distribution\n",
    "\n",
    "The first sampling strategy which we will implement is sampling from a normal distribution.\n",
    "\n",
    "We take the numpy.random.normal method.\n",
    "\n",
    "You can take a look at the [official documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html), if you are not familiar with it.\n",
    "\n",
    "Use the parameters from the Setup section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_normal = None\n",
    "\n",
    "# generate the treatment combinations with a normal distribution\n",
    "# add your code here\n",
    "\n",
    "# scale the treatment combinations to the range (-1, 1) with your scale function\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work? Let's inspect the result in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(treatments_normal[:, 0], treatments_normal[:, 1])\n",
    "plt.title('Random sampling from a normal distribution')\n",
    "plt.xlabel('Factor 1')\n",
    "plt.ylabel('Factor 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the result look like?\n",
    "\n",
    "Which areas were covered well and which less?\n",
    "\n",
    "Increase the sample size and re-run the code to see how the gathered treatmens change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from a uniform distribution\n",
    "\n",
    "The second sampling strategy which we will implement is sampling from a uniform distribution.\n",
    "\n",
    "We take the numpy.random.normal method.\n",
    "\n",
    "You can take a look at the [official documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html), if you are not familiar with it.\n",
    "\n",
    "Use the parameters from the Setup section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_uniform = None\n",
    "\n",
    "# generate the treatment combinations with a normal distribution\n",
    "# add your code here\n",
    "\n",
    "# scale the treatment combinations to the range (-1, 1) with your scale function\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work? Let's inspect the result in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(treatments_uniform[:, 0], treatments_uniform[:, 1])\n",
    "plt.title('Random sampling from a uniform distribution')\n",
    "plt.xlabel('Factor 1')\n",
    "plt.ylabel('Factor 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the result look like?\n",
    "\n",
    "Which areas were covered well and which less?\n",
    "\n",
    "Increase the sample size and re-run the code to see how the gathered treatmens change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from a Latin Hypercube\n",
    "\n",
    "Lastly, we will implement the latin hypercube strategy.\n",
    "\n",
    "For that we will take the scipy.stats.qmc.LatinHypercube method.\n",
    "\n",
    "Please make yourself familiar with it through the [official documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.qmc.LatinHypercube.html).\n",
    "\n",
    "And here again - use the parameters from the setup.\n",
    "\n",
    "Tip: We import the LatinHypercube class from scipy. Use the 'random' method of this class to create the treatment combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.qmc import LatinHypercube\n",
    "\n",
    "treatments_lhc = None\n",
    "\n",
    "# generate the treatment combinations with a normal distribution\n",
    "# add your code here\n",
    "\n",
    "# scale the treatment combinations to the range (-1, 1) with your scale function\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work? Let's inspect the result in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(treatments_lhc[:, 0], treatments_lhc[:, 1])\n",
    "plt.title('Random sampling from a Latin Hypercube')\n",
    "plt.xlabel('Factor 1')\n",
    "plt.ylabel('Factor 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the result look like?\n",
    "\n",
    "Which areas were covered well and which less?\n",
    "\n",
    "Does it look any different from the normal distribution?\n",
    "\n",
    "Increase the sample size and re-run the code to see how the gathered treatmens change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed analysis of the obtained results\n",
    "\n",
    "Here we will now analyze the obtained results with respect to their coverage.\n",
    "\n",
    "We will compute the coverage and plot a 2D histogram of the differently gathered treatments. \n",
    "\n",
    "This will give us a better idea of the differences - especially between uniform and Latin Hypercube sampling - than simple scatter plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First all, copy the sampling commands which you already implemented into the following cell so we do not have to re-run each cell when changing the sample size.\n",
    "\n",
    "(And don't forget to scale here as well)\n",
    "\n",
    "For the Latin Hypercube:\n",
    "    Make this time use of the 'optimization' keyword and watch the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "np.random.seed(0)\n",
    "\n",
    "treatments_normal = None\n",
    "treatments_uniform = None\n",
    "treatments_lhc = None\n",
    "\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the coverage of the treatments with respect to the design space!\n",
    "\n",
    "The steps for our analysis look as follows:\n",
    "1. Compute the target coverage which is $target=\\frac{n_\\text{samples}}{n_\\text{bins}**n_\\text{factors}}$\n",
    "2. Compute 2D Histograms for each of the methods where the number of samples per bin is counted\n",
    "3. Compute the bin-wide coverage for each method\n",
    "4. Compute under-, over- and highly over-represented bins ($bin_\\text{count}<target$; $bin_\\text{count}>target$; $bin_\\text{count}>target*threshold$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_bins = 10\n",
    "threshold_highly_overrepresented = 2\n",
    "\n",
    "# compute the target coverage\n",
    "target_coverage = np.max((n_samples/(hist_bins**n_factors), 1))\n",
    "threshold_highly_overrepresented = target_coverage * threshold_highly_overrepresented\n",
    "print(f'Target coverage: {target_coverage} samples per bin')\n",
    "\n",
    "# compute 2D histograms for each sampling method with the numpy method\n",
    "hist_normal = np.histogram2d(treatments_normal[:, 0], treatments_normal[:, 1], bins=hist_bins)[0]\n",
    "hist_uniform = np.histogram2d(treatments_uniform[:, 0], treatments_uniform[:, 1], bins=hist_bins)[0]\n",
    "hist_lhc = np.histogram2d(treatments_lhc[:, 0], treatments_lhc[:, 1], bins=hist_bins)[0]\n",
    "\n",
    "# compute the actual coverage for each sampling method\n",
    "coverage_normal = np.round(np.sum(hist_normal > 0)/(hist_bins**n_factors) * 100, 2)\n",
    "coverage_uniform = np.round(np.sum(hist_uniform > 0)/(hist_bins**n_factors) * 100, 2)\n",
    "coverage_lhc = np.round(np.sum(hist_lhc > 0)/(hist_bins**n_factors) * 100, 2)\n",
    "\n",
    "# compute the amount of underrepresented bins for each sampling method\n",
    "underrep_normal = round(np.sum(hist_normal < target_coverage)/(hist_bins**n_factors) * 100, 2)\n",
    "underrep_uniform = round(np.sum(hist_uniform < target_coverage)/(hist_bins**n_factors) * 100, 2)\n",
    "underrep_lhc = round(np.sum(hist_lhc < target_coverage)/(hist_bins**n_factors) * 100, 2)\n",
    "\n",
    "# compute the amount of overrepresented bins for each sampling method\n",
    "overrep_normal = round(np.sum(hist_normal > target_coverage)/(hist_bins**n_factors) * 100, 2)\n",
    "overrep_uniform = round(np.sum(hist_uniform > target_coverage)/(hist_bins**n_factors) * 100, 2)\n",
    "overrep_lhc = round(np.sum(hist_lhc > target_coverage)/(hist_bins**n_factors) * 100, 2)\n",
    "\n",
    "# compute the amount of highly overrepresented bins for each sampling method\n",
    "highly_overrep_normal = round(np.sum(hist_normal > threshold_highly_overrepresented)/(hist_bins**n_factors) * 100, 2)\n",
    "highly_overrep_uniform = round(np.sum(hist_uniform > threshold_highly_overrepresented)/(hist_bins**n_factors) * 100, 2)\n",
    "highly_overrep_lhc = round(np.sum(hist_lhc > threshold_highly_overrepresented)/(hist_bins**n_factors) * 100, 2)\n",
    "\n",
    "# print the results in a table\n",
    "print(f'{\"-\"*25:<25} {\"-\"*15:<15} {\"-\"*25:<25} {\"-\"*25:<25} {\"-\"*25:<25}')\n",
    "print(f'{\"Sampling method\":<25} {\"Coverage [%]\":<15} {\"Underrepresented [%]\":<25} {\"Overrepresented [%]\":<25} {\"Highly overrepresented [%]\":<25}')\n",
    "print(f'{\"-\"*25:<25} {\"-\"*15:<15} {\"-\"*25:<25} {\"-\"*25:<25} {\"-\"*25:<25}')\n",
    "print(f'{\"Normal distribution\":<25} {coverage_normal:<15} {underrep_normal:<25} {overrep_normal:<25} {highly_overrep_normal:<25}')\n",
    "print(f'{\"Uniform distribution\":<25} {coverage_uniform:<15} {underrep_uniform:<25} {overrep_uniform:<25} {highly_overrep_uniform:<25}')\n",
    "print(f'{\"Latin Hypercube\":<25} {coverage_lhc:<15} {underrep_lhc:<25} {overrep_lhc:<25} {highly_overrep_lhc:<25}')\n",
    "print(f'{\"-\"*25:<25} {\"-\"*15:<15} {\"-\"*25:<25} {\"-\"*25:<25} {\"-\"*25:<25}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the corresponding plots!\n",
    "\n",
    "The plotting is already implemented to make your life a little bit easier. \n",
    "\n",
    "You are still very welcome to go through the plotting code on your own as oftentimes this can be a quite challenging part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = True\n",
    "\n",
    "# make a figure with three subplots for the three sampling methods\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "# plot the samples from the normal distribution on the first subplot\n",
    "axes[0].hist2d(treatments_normal[:, 0], treatments_normal[:, 1], bins=hist_bins, cmap='Blues')\n",
    "if scatter:\n",
    "    axes[0].scatter(treatments_normal[:, 0], treatments_normal[:, 1], color='orange')\n",
    "axes[0].set_title('normal distribution')\n",
    "axes[0].set_xlabel('Factor 1')\n",
    "axes[0].set_ylabel('Factor 2')\n",
    "\n",
    "# plot the samples from the uniform distribution on the second subplot\n",
    "axes[1].hist2d(treatments_uniform[:, 0], treatments_uniform[:, 1], bins=hist_bins, cmap='Blues')\n",
    "if scatter:\n",
    "    axes[1].scatter(treatments_uniform[:, 0], treatments_uniform[:, 1], color='orange')\n",
    "axes[1].set_title('uniform distribution')\n",
    "axes[1].set_xlabel('Factor 1')\n",
    "\n",
    "# plot the LHS samples on the third subplot\n",
    "axes[2].hist2d(treatments_lhc[:, 0], treatments_lhc[:, 1], bins=hist_bins, cmap='Blues')\n",
    "if scatter:\n",
    "    axes[2].scatter(treatments_lhc[:, 0], treatments_lhc[:, 1], color='orange')\n",
    "axes[2].set_title('Latin Hypercube')\n",
    "axes[2].set_xlabel('Factor 1')\n",
    "\n",
    "# set figure title\n",
    "fig.suptitle('Sampling from')\n",
    "\n",
    "# share y axis\n",
    "axes[1].sharey(axes[0])\n",
    "axes[2].sharey(axes[0])\n",
    "# hide y axis for the second and third subplot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "axes[2].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing all these analysis: What's your impression of the different random sampling methods?\n",
    "\n",
    "Can you think of use-cases for each of the method?\n",
    "\n",
    "Can you tell now a difference between the uniform and Latin Hypercube sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You've finished the tutorial on random sampling!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
