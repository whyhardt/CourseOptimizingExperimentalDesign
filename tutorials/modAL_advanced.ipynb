{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced usage of modAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is about providing you even more knowledge about the powerful key features of the *modAL* package.\n",
    "\n",
    "After you've already learned about the basics of active learning it's time to delve into the different possibilities *modAL* holds up for you.\n",
    "\n",
    "In this tutorial you will:\n",
    "- Learn to use different types of active learner models\n",
    "- Get to know different types of sampling strategies for each introduced active learner model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install modAL you can use this command which will install the package directly from source:\n",
    "\n",
    "`%pip install git+https://github.com/modAL-python/modAL.git`\n",
    "\n",
    "(Remove `%` if you are running this command from your terminal or from a .py-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install git+https://github.com/modAL-python/modAL.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Committee Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the popular active learning strategies is the Query by Committee (also: Ensemble), where we keep several hypotheses (i.e. trained classifiers) about the data, and we select our queries by measuring the disagreement of the hypotheses. In modAL, this model is implemented in the `Committee` and `CommitteeRegressor` class.\n",
    "\n",
    "In this section we will learn more about the `CommitteeRegressor` because it provides a neat way of obtaining the uncertainty about a point completely independent of the chosen type of estimation model. Ensemble regression models can be used therefore in a broad set of scenarios, because the standard deviation of the predictions at a given point can be thought of as a measure of disagreement. Hence, we get an uncertainty estimation delivered for free by training multiple models at once!\n",
    "\n",
    "Isn't that great? Let's check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same ground truth as we had in the previous tutorial about active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# training data\n",
    "x_training = np.random.choice(np.linspace(0, 20, 10000), size=200, replace=False).reshape(-1, 1)\n",
    "ground_truth = lambda x: np.sin(x) + np.random.normal(scale=0.3, size=x.shape)\n",
    "y_training = ground_truth(x_training)\n",
    "\n",
    "# test data\n",
    "x_test = np.linspace(0, 20, 1000)\n",
    "y_test = ground_truth(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x_training, y_training, c='k', s=20)\n",
    "plt.title('sin(x) + noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have several regressors, measuring disagreement can be done by calculating the standard deviation of the predictions for each point. In the simplest setting, this is implemented in the function `modAL.disagreement.max_std_sampling`.\n",
    "\n",
    "This measure is default for `CommitteeRegressors`, so we donâ€™t need to specify this upon initialization.\n",
    "Let's define the active learner and train it with some random initial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner, CommitteeRegressor\n",
    "from modAL.disagreement import max_std_sampling\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor as model\n",
    "\n",
    "n_initial = 15  # initial amount of random samples\n",
    "n_regressor = 3 # number of regressors in the ensemble; n_initial samples are divided evenly among the regressors\n",
    "\n",
    "# get initial training data - random samples\n",
    "initial_idx = np.random.choice(range(len(x_training)), size=n_initial, replace=False)  # draw random initial indices\n",
    "initial_idx = initial_idx.reshape(-1, n_regressor)  # reshape to list of lists\n",
    "\n",
    "# define a kernel for the Gaussian process regressor\n",
    "# RBF will approximate the non-linearities and WhiteKernel will add noise to the model\n",
    "kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "         + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "\n",
    "# first we have to initialize the single active learners\n",
    "# in this case each learner will be trained on only one sample\n",
    "learner_list = []\n",
    "for idx_learner in range(initial_idx.shape[1]):\n",
    "    learner_list.append(\n",
    "        ActiveLearner(\n",
    "            estimator=GPR(kernel),\n",
    "            X_training=x_training[initial_idx[:, idx_learner]].reshape(-1, 1), y_training=y_training[initial_idx[:, idx_learner]].reshape(-1, 1),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# initializing the Committee\n",
    "committee = CommitteeRegressor(\n",
    "    learner_list=learner_list,\n",
    "    query_strategy=max_std_sampling\n",
    ")\n",
    "\n",
    "print(f'Number of learners in the committee: {len(committee)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the initial prediction of our ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# let's define a plotting method that we can reuse throughout the experiment\n",
    "def plotting_method(committee: CommitteeRegressor, x, x_true=None, y_true=None, mse=None, x_new=None, x_querried=None, y_querried=None):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for learner_idx, learner in enumerate(committee):\n",
    "        plt.plot(x, learner.predict(x.reshape(-1, 1)), linewidth=2)\n",
    "    \n",
    "    if x_true is not None and y_true is not None:\n",
    "        plt.scatter(x_true, y_true, c='grey')\n",
    "    plt.title('Predictions of the single regressors')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    pred, std = committee.predict(x.reshape(-1, 1), return_std=True)\n",
    "    pred = pred.reshape(-1, )\n",
    "    std = std.reshape(-1, )\n",
    "    plt.plot(x, pred, c='r', linewidth=2)\n",
    "    plt.fill_between(x, pred - std, pred + std, alpha=0.2)\n",
    "    if x_true is not None and y_true is not None:\n",
    "        plt.scatter(x_true, y_true, c='grey')\n",
    "    if x_new is not None:\n",
    "    # make a vertical line to indicate the new training sample\n",
    "        if isinstance(x_new, int):\n",
    "            x_new = [x_new]\n",
    "        for x in x_new:\n",
    "            plt.axvline(x=x, c='r', linestyle='--')\n",
    "    if x_querried is not None and y_querried is not None:\n",
    "        plt.plot(x_querried, y_querried, 'x', color='red', label='Querried samples')\n",
    "    if mse is not None:\n",
    "        plt.title(f'Prediction of the ensemble\\nMSE of the ensemble: {mse:.3f}')\n",
    "    else:\n",
    "        plt.title('Prediction of the ensemble')\n",
    "    plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test, committee.predict(x_test.reshape(-1, 1)))\n",
    "plotting_method(committee, x_test, x_true=x_training, y_true=y_training, mse=mse)  # plot the initial predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to do active learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_queries = 1\n",
    "\n",
    "query_idx, query_instances = committee.query(x_training, n_instances=n_queries)  # get the query points from the regressor which are expected to be the most informative\n",
    "committee.teach(x_training[query_idx].reshape(-1, 1), y_training[query_idx].reshape(-1, 1))  # fit the model with the query points\n",
    "\n",
    "mse = mean_squared_error(y_test, committee.predict(x_test.reshape(-1, 1)))\n",
    "plotting_method(committee, x_test, x_true=x_training, y_true=y_training, x_new=query_instances, mse=mse)  # plot the predictions after the first query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it look already any better?\n",
    "\n",
    "What happened from the initial plot to the second one?\n",
    "\n",
    "Let's iterate a few more times and check the result after each iteration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "\n",
    "for _ in range(iterations):\n",
    "    query_idx, query_instance = committee.query(x_training, n_instances=n_queries)  # get the query points from the regressor which are expected to be the most informative\n",
    "    committee.teach(x_training[query_idx].reshape(-1, 1), y_training[query_idx].reshape(-1, 1))  # fit the model with the query points\n",
    "    \n",
    "    # compute the mean squared error\n",
    "    mse = mean_squared_error(y_test, committee.predict(x_test.reshape(-1, 1)))\n",
    "\n",
    "    plotting_method(committee, x_test, x_true=x_training, y_true=y_training, x_new=x_training[query_idx], mse=mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the difference between a single active learner (as you have seen its behavior in the last tutorial) and the `CommitteeRegressor` in terms of their expected behavior?\n",
    "\n",
    "As a practice and to get a feeling for the `CommitteeRegressor` try to tweak following parameters and see what happens:\n",
    "- increase the noise of the ground truth\n",
    "- increase the number of initial samples\n",
    "- increase the number of regressors in the ensemble\n",
    "- increase the number of queries per iteration\n",
    "\n",
    "Compare also with the `ActiveLearner` model and random sampling from the last tutorial.\n",
    "\n",
    "In which scenarios is the `CommitteeRegressor` most useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Bayesian optimization, instead of picking queries by maximizing the uncertainty of predictions, function values are evaluated at points where the promise of finding a better value is large. In *modAL*, these algorithms are implemented with the `BayesianOptimizer` class, which is a sibling of `ActiveLearner`. Initializing a `BayesianOptimizer` is syntactically identical to the initialization of `ActiveLearner`, although there is an important difference.\n",
    "\n",
    "In Bayesian optimization, a so-called acquisition funciton is used instead of the uncertainty based utility measures of active learning. In *modAL*, Bayesian optimization algorithms are implemented in the `modAL.models.BayesianOptimizer` class. Currently, there are three available acquisition functions in the `modAL.acquisition` module: expected improvement `max_EI`, probability of improvement `max_PI` and upper confidence bounds `max_UCB`. You can find more information about them and the mathematical reasoning behind them [here](https://modal-python.readthedocs.io/en/latest/content/query_strategies/Acquisition-functions.html).\n",
    "\n",
    "Let's initialize the `BayesianOptimizer` in the first step. Here we will start with the acquisition function for maximizing the expected improvement `max_EI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import BayesianOptimizer\n",
    "from modAL.acquisition import max_EI, max_PI, max_UCB\n",
    "\n",
    "n_initial = 5  # initial number of points\n",
    "initial_idx = np.random.choice(range(len(x_training)), size=n_initial, replace=False)  # draw random initial indices\n",
    "\n",
    "# we will use the same kernel as before\n",
    "optimizer = BayesianOptimizer(\n",
    "    estimator=GPR(kernel),\n",
    "    query_strategy=max_EI,\n",
    "    X_training=x_training[initial_idx].reshape(-1, 1), y_training=y_training[initial_idx].reshape(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a re-usable plotting_method for the `BayesianOptimizer` and check how it performs.\n",
    "\n",
    "We will simply take the plotting method from the `ActiveLearner` tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred, y_std = optimizer.predict(x_test.reshape(-1, 1), return_std=True)\n",
    "y_pred, y_std = y_pred.ravel(), y_std.ravel()\n",
    "\n",
    "# compute the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# plotting method which we can reuse later\n",
    "def plotting_method(x1, y1, y1_std, x_true=None, y_true=None, mse=None, x_new=None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x1, y1, label='Prediction')\n",
    "    plt.fill_between(x1, y1 - y1_std, y1 + y1_std, alpha=0.2)\n",
    "    if x_true is not None and y_true is not None:\n",
    "        plt.scatter(x_true, y_true, c='grey', s=20, label='Training samples')\n",
    "    if x_new is not None:\n",
    "        # make a vertical line to indicate the new training sample\n",
    "        if isinstance(x_new, (int, float)):\n",
    "            x_new = [x_new]\n",
    "        for x in x_new:\n",
    "            plt.axvline(x=x, c='r', linestyle='--', label='New query')\n",
    "    if mse is not None:\n",
    "        plt.title(f'Prediction over the whole grid (mse={np.round(mse, 4)})')\n",
    "    else:\n",
    "        plt.title('Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotting_method(x_test, y_pred, y_std, x_true=x_training, y_true=y_training, mse=mse, x_new=x_training[initial_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it look? Is there anything familiar in this plot?\n",
    "\n",
    "Let's train on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "\n",
    "for _ in range(iterations):\n",
    "    query_idx, query_instance = optimizer.query(x_training, n_instances=n_queries)  # get the query points from the regressor which are expected to be the most informative\n",
    "    optimizer.teach(x_training[query_idx].reshape(-1, 1), y_training[query_idx].reshape(-1, 1))  # fit the model with the query points\n",
    "    \n",
    "    # get the predicted response and the standard deviation\n",
    "    y_pred, y_std = optimizer.predict(x_test.reshape(-1, 1), return_std=True)\n",
    "    # y_pred, y_std = y_pred.ravel(), y_std.ravel()\n",
    "\n",
    "    # compute the mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    plotting_method(x_test, y_pred, y_std, x_true=x_training, y_true=y_training, mse=mse, x_new=x_training[query_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the acquisition function doing exactly?\n",
    "\n",
    "Try the other ones as well, play with the hyperparameters and compare the new behavior with the seen ones.\n",
    "\n",
    "When might the `BayesianOptimizer` be most useful? Where are its downsides?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've finished the advanced tutorial for active learning and the *modAL* package.\n",
    "\n",
    "As you have maybe noticed, active learning needs some/a lot of informed hyperparameter tweaking and twisting. Further, there's not the one solution for every case. Active learning should be used where it is expected to bring benefits and not just blindly being adapted in every imaginable scenario.\n",
    "\n",
    "You've seen now some of the most popular and very distinct ways for optimizing experimental design."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
